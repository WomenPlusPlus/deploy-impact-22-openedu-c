{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeaoTD4itI1I"
   },
   "source": [
    "<center><a target=\"_blank\" href=\"https://www.womenplusplus.ch/deploy-impact/\"><img src=\"https://drive.google.com/uc?id=1eOWdijaay1bv94PlIRMqNt7eWmUfAI2u\" width=\"500\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
    "\n",
    "<center><a target=\"_blank\" href=\"https://learning.sit.org/\"><img src=\"https://drive.google.com/uc?id=1x9_jQgLhozCSWDSaOdVxKmxOEAe_OLgV\" width=\"250\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
    "\n",
    "_____\n",
    "\n",
    "<center> <h1> Live Coding - Topic Modelling </h1> </center>\n",
    "\n",
    "<p style=\"margin-bottom:1cm;\"></p>\n",
    "\n",
    "_____\n",
    "\n",
    "<center>SIT Learning, 2022</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iKMVCis12aq"
   },
   "source": [
    "# Topic Modeling on Research Papers\n",
    "\n",
    "We will do an interesting exercise here—build topic models on past research papers\n",
    "from the very popular NIPS conference (now known as the NeurIPS conference). The\n",
    "late professor Sam Roweis compiled an excellent collection of NIPS Conference Papers\n",
    "from Volume 1 – 12, which you can find at https://cs.nyu.edu/~roweis/data.html.\n",
    "An interesting fact is that he obtained this by massaging the OCR’d data from NIPS\n",
    "1-12, which was actually the pre-electronic submission era. Yann LeCun made the data\n",
    "available. There is an even more updated dataset available up to NIPS 17 at http://\n",
    "ai.stanford.edu/~gal/data.html. However, that dataset is in the form of a MAT file, so\n",
    "you might need to do some additional preprocessing before working on it in Python.\n",
    "\n",
    "\n",
    "# The Main Objective\n",
    "\n",
    "Considering our discussion so far, our main objective is pretty simple. Given a whole\n",
    "bunch of conference research papers, can we identify some key themes or topics from\n",
    "these papers by leveraging unsupervised learning? We do not have the liberty of labeled\n",
    "categories telling us what the major themes of every research paper are. Besides that, we\n",
    "are dealing with text data extracted using OCR (optical character recognition). Hence,\n",
    "you can expect misspelled words, words with characters missing, and so on, which\n",
    "makes our problem even more challenging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsTqya546U6q"
   },
   "source": [
    "# Download Data and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4298,
     "status": "ok",
     "timestamp": 1666801117011,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "BJaNFsqQ6KGt",
    "outputId": "d9998acb-9f6c-4c3e-c5ba-c1e72fb63634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-26 16:18:32--  https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
      "Resolving cs.nyu.edu (cs.nyu.edu)... 216.165.22.203\n",
      "Connecting to cs.nyu.edu (cs.nyu.edu)|216.165.22.203|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12851423 (12M) [application/x-gzip]\n",
      "Saving to: ‘nips12raw_str602.tgz.1’\n",
      "\n",
      "nips12raw_str602.tg 100%[===================>]  12.26M  4.96MB/s    in 2.5s    \n",
      "\n",
      "2022-10-26 16:18:35 (4.96 MB/s) - ‘nips12raw_str602.tgz.1’ saved [12851423/12851423]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz\n",
    "!tar -xzf nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6701,
     "status": "ok",
     "timestamp": 1666801123709,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "C36S18zo8w3b",
    "outputId": "5a351387-026f-4284-bbc8-68e17802a1ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "import nltk\n",
    "nltk.download('punkt') # tokenization\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') # lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666801123709,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "oHpf-YxR6XuW",
    "outputId": "f7460641-59a6-4672-d3b1-3f2f327d7783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nips00', 'nips12', 'README_yann', 'nips01', 'MATLAB_NOTES', 'nips05', 'nips08', 'idx', 'nips09', 'nips07', 'RAW_DATA_NOTES', 'nips04', 'nips06', 'nips11', 'nips02', 'nips03', 'nips10', 'orig']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y20UiwtA6pAg"
   },
   "source": [
    "# Load NIPS Research Papers Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1666801124267,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "D3G8nUsJ6h7V",
    "outputId": "42a7a533-9601-45c0-f858-12bce0f13f90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
    "# Read all texts into a list.\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1666801128250,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "ERKoH06O3vuI",
    "outputId": "31de25f2-5bcf-4852-d75f-f7853312e8d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1666801128623,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "JaTh1Jll6kx9",
    "outputId": "d7550353-b0d9-4546-d3e5-11e347ebf9ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317 \n",
      "PARTITIONING OF SENSORY DATA BY A COPTICAI, NETWOPK  \n",
      "Richard Granger, Jos Ambros-Ingerson, Howard Henry, Gary Lynch \n",
      "Center for the Neurobiology of Learning and Memory \n",
      "University of California \n",
      "Irvine, CA, 91717 \n",
      "ABSTRACT\n",
      "To process sensory data, sensory brain areas must preserve information about both \n",
      "the similarities and differences among learned cues: without the latter, acuity would \n",
      "be lost, whereas without the former, degraded versions of a cue would be erroneously \n",
      "thought to be distinct cues, and would not be recognized. We have constructed a \n",
      "model of piriform cortex incorporating a large number of biophysical, anatomical and \n",
      "physiological parameters, such as two-step excitatory firing thresholds, necessary and \n",
      "suicient conditions for long-term potentiation (LTP) of synapses, three distinct types \n",
      "of inhibitory currents (short IPSPs, long hyperpolarizing currents (LHP) and long cell- \n",
      "specific afterhyperpolarization (AHP)), sparse connectivity between bulb and l\n"
     ]
    }
   ],
   "source": [
    "print(papers[3][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNqkh2nb8qpe"
   },
   "source": [
    "# Basic Text Pre-processing\n",
    "\n",
    "We perform some basic text wrangling or preprocessing before diving into topic\n",
    "modeling. We keep things simple here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53470,
     "status": "ok",
     "timestamp": 1666801183217,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "Jhsbee7g8lwa",
    "outputId": "3d3db1c9-7525-45f4-ba7e-45337e28e5c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "100%|██████████| 1740/1740 [00:52<00:00, 32.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "CPU times: user 42.2 s, sys: 842 ms, total: 43 s\n",
      "Wall time: 53.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import nltk # Natural Language Toolkit library\n",
    "import tqdm # Fancy progress bar\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+') # can also use nltk.word_tokenize to get word tokens for each paper\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in tqdm.tqdm(papers):\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1] # removing any single character words \\ numbers \\ symbols \n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "            \n",
    "    return norm_papers\n",
    "    \n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1666801183566,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "Cq4EhTwP-I_U",
    "outputId": "321b3c38-731e-4e07-90dd-8286a5f84661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lti6h', 'density', 'associative', 'ories', 'ir', 'dembo', 'information', 'system', 'laboratory', 'stanford', 'university', 'stanford', 'ca', 'ofer', 'ze', 'itouni', 'laboratory', 'informat', 'ion', 'dec', 'ion', 'system', 'mit', 'cambridge', 'abstract', 'class', 'high', 'density', 'associative', 'memory', 'constr', 'cted', 'starting', 'description', 'de', 'ired', 'property', 'exhibit', 'property', 'include', 'high', 'capacity', 'oontrollable', 'basin', 'attraction', 'fast', 'speed', 'convergence', 'ortunately', 'enough']\n"
     ]
    }
   ],
   "source": [
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFubckun_IYp"
   },
   "source": [
    "# Build a Bi-gram Phrase Model\n",
    "\n",
    "Before feature engineering and vectorization, we want to extract some useful bi-gram\n",
    "based phrases from our research papers and remove some unnecessary terms. We\n",
    "leverage the very useful gensim.models.Phrases class for this. This capability helps us\n",
    "automatically detect common phrases from a stream of sentences, which are typically\n",
    "multi-word expressions/word n-grams. \n",
    "\n",
    "This implementation draws inspiration\n",
    "from the famous paper by Mikolov, et al., “Distributed Representations of Words and\n",
    "Phrases and their Compositionality,” which you can check out at https://arxiv.org/\n",
    "abs/1310.4546. We start by extracting and generating words and bi-grams as phrases for\n",
    "each tokenized research paper. \n",
    "\n",
    "We leverage the `min_count` parameter, which tells us that our model ignores all words and bi-grams with total\n",
    "collected count lower than 20 across the corpus (of the input paper as a list of tokenized\n",
    "sentences). We also use a `threshold` of 20, which tells us that the model accepts specific\n",
    "phrases based on this threshold value so that a phrase of words `\"a followed by b\"` is\n",
    "accepted if the score of the phrase is greater than the threshold of 20. This threshold is\n",
    "dependent on the scoring parameter, which helps us understand how these phrases are\n",
    "scored to understand their influence.\n",
    "Typically the default scorer is used and it’s pretty straightforward to understand.\n",
    "You can check out further details in the documentation at https://radimrehurek.com/gensim/models/phrases.html#gensim.models.phrases.original_scorer and in the\n",
    "previously mentioned research paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1666801183567,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "RWq3XtcEf21F",
    "outputId": "548a9f03-55d2-4c79-a391-b0b4c6181d81"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'3.6.0'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__ # version 3.6 needed to run MALLET LDA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23309,
     "status": "ok",
     "timestamp": 1666801206874,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "6IX3-ZbQ-fXp",
    "outputId": "312360c5-b70a-4608-c367-a8bf0f8f782d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lti6h', 'density', 'associative', 'ories', 'ir', 'dembo', 'information', 'system', 'laboratory', 'stanford_university', 'stanford_ca', 'ofer', 'ze', 'itouni', 'laboratory', 'informat', 'ion', 'dec', 'ion', 'system', 'mit', 'cambridge_abstract', 'class', 'high', 'density', 'associative_memory', 'constr', 'cted', 'starting', 'description', 'de', 'ired', 'property', 'exhibit', 'property', 'include', 'high', 'capacity', 'oontrollable', 'basin_attraction', 'fast', 'speed', 'convergence', 'ortunately', 'enough', 'resulting', 'memory', 'implementable', 'artificial_neural', 'net']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, threshold=20) # higher threshold fewer phrases.\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "print(bigram_model[norm_papers[0]][:50]) # very similar to using ngram_range=(1,2) in count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666801206875,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "_kiV5zd1cPM5"
   },
   "outputs": [],
   "source": [
    "#bigram_model[norm_papers[-1][:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10373,
     "status": "ok",
     "timestamp": 1666801217244,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "KaGCzYSU-jx1",
    "outputId": "175b07e8-4f86-44a4-a6a0-3600c8cd8360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, '0on'), (1, '0pn'), (2, '1an'), (3, '1coat'), (4, '2__'), (5, '2ai'), (6, '2f'), (7, '2m'), (8, '2r'), (9, '3a'), (10, '4a'), (11, '4b'), (12, '4c'), (13, '4d'), (14, '4e')]\n",
      "Total Vocabulary Size: 78892\n"
     ]
    }
   ],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x47ztNpD12bC"
   },
   "source": [
    "Looks like we have a lot of unique phrases in our corpus of research papers,\n",
    "based on the preceding output. Several of these terms are not very useful since they are\n",
    "specific to a paper or even a paragraph in a research paper. Hence, it is time to prune\n",
    "our vocabulary and start removing terms. Leveraging document frequency is a great way\n",
    "to achieve this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1666801217244,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "YTiZ2Bxe-tNK",
    "outputId": "9232755c-d749-4464-ac10-7d4fca40d958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 7756\n"
     ]
    }
   ],
   "source": [
    "# Filter out words that occur less than 20 documents, or more than 60% of the documents.\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6) # similar to min_df and max_df in count vectorizer\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKMDWQ6W12bF"
   },
   "source": [
    "We removed all terms that occur fewer than 20 times across all documents and all\n",
    "terms that occur in more than 60% of all the documents. We are interested in finding\n",
    "different themes and topics and not recurring themes. Hence, this suits our scenario\n",
    "perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kj2lB4_b_eFO"
   },
   "source": [
    "# Transforming corpus into bag of words vectors\n",
    "\n",
    "We can now perform feature engineering by leveraging a simple Bag of Words model. In BOW a text (such as a sentence or a document) is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1666801217244,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "mBQMJaVOeKiL"
   },
   "outputs": [],
   "source": [
    "# norm_corpus_bigrams[0][:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1600,
     "status": "ok",
     "timestamp": 1666801218831,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "cp_fhm91-3R-",
    "outputId": "b60dbf5a-3678-4521-fb1a-5a78a6ec46e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9, 1), (21, 1), (22, 2), (24, 1), (31, 1), (39, 1), (47, 11), (51, 2), (53, 3), (65, 1), (70, 1), (71, 4), (74, 1), (80, 1), (81, 1), (89, 10), (97, 44), (101, 1), (108, 1), (111, 1), (138, 1), (143, 1), (150, 1), (154, 5), (175, 1), (178, 2), (180, 2), (187, 1), (215, 1), (222, 1), (240, 4), (249, 3), (252, 1), (257, 1), (260, 3), (266, 1), (268, 1), (269, 1), (274, 1), (279, 1), (285, 1), (286, 7), (287, 2), (293, 1), (296, 2), (297, 2), (309, 1), (312, 2), (316, 6), (317, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Transforming corpus into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666801218831,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "_oOA652d-6sI",
    "outputId": "ef4381b4-378e-4cd4-fd41-5315158119b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('according', 1), ('always', 1), ('american_institute', 2), ('analyzed', 1), ('arbitrary', 1), ('assume', 1), ('behavior', 11), ('bound', 2), ('bounded', 3), ('change', 1), ('choose', 1), ('chosen', 4), ('clear', 1), ('comparison', 1), ('complete', 1), ('constant', 10), ('convergence', 44), ('corresponding', 1), ('defined', 1), ('denote', 1), ('easily', 1), ('el', 1), ('energy', 1), ('equation', 5), ('extremely', 1), ('fast', 2), ('fig', 2), ('follows', 1), ('include', 1), ('initial', 1), ('iteration', 4), ('le', 3), ('let', 1), ('linear', 1), ('location', 3), ('mainly', 1), ('measure', 1), ('memory', 1), ('mit', 1), ('natural', 1), ('neural', 1), ('neuron', 7), ('next', 2), ('note', 1), ('operation', 2), ('optimal', 2), ('particular', 1), ('physic', 2), ('position', 6), ('positive', 1)]\n"
     ]
    }
   ],
   "source": [
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666801218831,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "aAjuxxdH--fn",
    "outputId": "9615b0db-6a9f-4c9e-e494-83047b6c76c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers: 1740\n"
     ]
    }
   ],
   "source": [
    "print('Total number of papers:', len(bow_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUb8ZKJXJI-4"
   },
   "source": [
    "# Topic Models with Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "The Latent Dirichlet Allocation (LDA) technique is a generative probabilistic model in\n",
    "which each document is assumed to have a combination of topics similar to a probabilistic\n",
    "Latent Semantic Indexing model. In this case, the latent topics contain a Dirichlet\n",
    "prior over them. The math behind in this technique is pretty involved, so we will try to\n",
    "summarize it since going it specific details is out of the current scope.\n",
    "\n",
    "![](https://i.imgur.com/l23JAvE.png)\n",
    "\n",
    "Simplyfying the LDA model process:\n",
    "\n",
    "![](https://i.imgur.com/0BXCaUi.png)\n",
    "\n",
    "![](https://i.imgur.com/ioiUAxX.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104788,
     "status": "ok",
     "timestamp": 1666801323616,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "083_UQPlJZy_",
    "outputId": "a2123ea5-9f71-4ec3-b4c3-cb7b42850a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 2.35 s, total: 1min 41s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TOTAL_TOPICS = 10\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, \n",
    "                                   id2word=dictionary, chunksize=1740, \n",
    "                                   alpha='auto', eta='auto', random_state=42,\n",
    "                                   iterations=500, num_topics=TOTAL_TOPICS, \n",
    "                                   passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666801323617,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "IF9KX9UARO1r",
    "outputId": "c92cd39a-e481-4675-f881-4e19a79c6131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.010*\"equation\" + 0.009*\"state\" + 0.008*\"dynamic\" + 0.006*\"matrix\" + 0.006*\"vector\" + 0.006*\"rate\" + 0.006*\"convergence\" + 0.005*\"neuron\" + 0.005*\"solution\" + 0.004*\"noise\" + 0.004*\"gradient\" + 0.004*\"optimal\" + 0.004*\"eq\" + 0.004*\"fixed_point\" + 0.003*\"constant\" + 0.003*\"stochastic\" + 0.003*\"let\" + 0.003*\"theory\" + 0.003*\"step\" + 0.003*\"approximation\"\n",
      "\n",
      "Topic #2:\n",
      "0.010*\"training\" + 0.008*\"noise\" + 0.008*\"pattern\" + 0.007*\"rule\" + 0.006*\"ensemble\" + 0.005*\"unit\" + 0.005*\"subject\" + 0.005*\"task\" + 0.005*\"signal\" + 0.005*\"test\" + 0.004*\"prediction\" + 0.004*\"generalization\" + 0.004*\"experiment\" + 0.004*\"target\" + 0.004*\"trained\" + 0.003*\"training_set\" + 0.003*\"response\" + 0.003*\"ica\" + 0.003*\"measure\" + 0.003*\"pruning\"\n",
      "\n",
      "Topic #3:\n",
      "0.033*\"image\" + 0.013*\"unit\" + 0.009*\"object\" + 0.007*\"feature\" + 0.007*\"layer\" + 0.007*\"pixel\" + 0.006*\"vector\" + 0.005*\"local\" + 0.004*\"linear\" + 0.004*\"view\" + 0.004*\"pattern\" + 0.004*\"shape\" + 0.004*\"filter\" + 0.003*\"representation\" + 0.003*\"region\" + 0.003*\"surface\" + 0.003*\"constraint\" + 0.003*\"transformation\" + 0.003*\"gaussian\" + 0.003*\"scale\"\n",
      "\n",
      "Topic #4:\n",
      "0.008*\"distribution\" + 0.007*\"probability\" + 0.007*\"state\" + 0.006*\"variable\" + 0.006*\"estimate\" + 0.006*\"prior\" + 0.005*\"gaussian\" + 0.005*\"bayesian\" + 0.004*\"mixture\" + 0.004*\"sample\" + 0.004*\"density\" + 0.004*\"approximation\" + 0.004*\"training\" + 0.004*\"vector\" + 0.004*\"step\" + 0.004*\"likelihood\" + 0.003*\"class\" + 0.003*\"structure\" + 0.003*\"variance\" + 0.003*\"component\"\n",
      "\n",
      "Topic #5:\n",
      "0.015*\"cell\" + 0.008*\"stimulus\" + 0.008*\"pattern\" + 0.008*\"unit\" + 0.008*\"visual\" + 0.007*\"response\" + 0.007*\"activity\" + 0.006*\"neuron\" + 0.006*\"map\" + 0.005*\"motion\" + 0.005*\"layer\" + 0.004*\"object\" + 0.004*\"cortical\" + 0.004*\"feature\" + 0.004*\"spatial\" + 0.004*\"representation\" + 0.004*\"direction\" + 0.004*\"cortex\" + 0.004*\"connection\" + 0.004*\"orientation\"\n",
      "\n",
      "Topic #6:\n",
      "0.013*\"training\" + 0.009*\"word\" + 0.009*\"unit\" + 0.008*\"feature\" + 0.008*\"recognition\" + 0.006*\"task\" + 0.006*\"pattern\" + 0.006*\"trained\" + 0.005*\"net\" + 0.005*\"sequence\" + 0.005*\"representation\" + 0.005*\"architecture\" + 0.005*\"node\" + 0.005*\"layer\" + 0.005*\"speech\" + 0.004*\"classifier\" + 0.004*\"class\" + 0.004*\"classification\" + 0.004*\"context\" + 0.004*\"character\"\n",
      "\n",
      "Topic #7:\n",
      "0.026*\"state\" + 0.012*\"action\" + 0.010*\"control\" + 0.007*\"policy\" + 0.007*\"step\" + 0.006*\"task\" + 0.006*\"reinforcement_learning\" + 0.005*\"environment\" + 0.005*\"optimal\" + 0.005*\"robot\" + 0.004*\"controller\" + 0.004*\"goal\" + 0.004*\"reward\" + 0.003*\"machine\" + 0.003*\"agent\" + 0.003*\"cost\" + 0.003*\"current\" + 0.003*\"trajectory\" + 0.003*\"trial\" + 0.003*\"td\"\n",
      "\n",
      "Topic #8:\n",
      "0.007*\"class\" + 0.007*\"training\" + 0.006*\"size\" + 0.005*\"vector\" + 0.005*\"bound\" + 0.005*\"let\" + 0.004*\"linear\" + 0.004*\"node\" + 0.004*\"probability\" + 0.004*\"threshold\" + 0.004*\"theorem\" + 0.004*\"unit\" + 0.003*\"complexity\" + 0.003*\"theory\" + 0.003*\"distribution\" + 0.003*\"solution\" + 0.003*\"machine\" + 0.003*\"training_set\" + 0.003*\"consider\" + 0.003*\"sample\"\n",
      "\n",
      "Topic #9:\n",
      "0.024*\"neuron\" + 0.010*\"circuit\" + 0.008*\"current\" + 0.008*\"chip\" + 0.007*\"signal\" + 0.007*\"spike\" + 0.006*\"voltage\" + 0.006*\"cell\" + 0.005*\"neural\" + 0.005*\"frequency\" + 0.005*\"response\" + 0.005*\"analog\" + 0.005*\"synaptic\" + 0.004*\"channel\" + 0.004*\"firing\" + 0.004*\"threshold\" + 0.004*\"synapse\" + 0.003*\"connection\" + 0.003*\"pattern\" + 0.003*\"synapsis\"\n",
      "\n",
      "Topic #10:\n",
      "0.009*\"training\" + 0.008*\"vector\" + 0.007*\"signal\" + 0.007*\"control\" + 0.006*\"linear\" + 0.005*\"classifier\" + 0.005*\"nonlinear\" + 0.005*\"expert\" + 0.004*\"class\" + 0.004*\"node\" + 0.004*\"classification\" + 0.004*\"architecture\" + 0.004*\"trajectory\" + 0.004*\"prediction\" + 0.004*\"mapping\" + 0.003*\"adaptive\" + 0.003*\"dynamic\" + 0.003*\"sample\" + 0.003*\"local\" + 0.003*\"trained\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1666801324067,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "4jExj9SYRRyE",
    "outputId": "ec2f3436-7ce8-4a54-8169-383867844607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score: -1.0490426136710163\n"
     ]
    }
   ],
   "source": [
    "topics_coherences = lda_model.top_topics(bow_corpus, topn=20) # topn - top n words in the topic \n",
    "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
    "print('Avg. Coherence Score:', avg_coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666794837673,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "AHzKijy9hWAX"
   },
   "outputs": [],
   "source": [
    "#topics_coherences[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtPTIGeQ12by"
   },
   "source": [
    "Topic coherence is a complex topic in its own and it can be used to measure the\n",
    "quality of topic models to some extent. Typically, a set of statements is said to be\n",
    "coherent if they support each other. Topic models are unsupervised learning based\n",
    "models that are trained on unstructured text data, making it difficult to measure the\n",
    "quality of outputs. \n",
    "\n",
    "Refer to Text Analytics with Python 2nd Edition for more detail on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666801324068,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "azEdB08qRX4z",
    "outputId": "f409864d-9a62-43c2-b31e-be1a8233ce00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "[('distribution', 0.008), ('probability', 0.007), ('state', 0.007), ('variable', 0.006), ('estimate', 0.006), ('prior', 0.006), ('gaussian', 0.005), ('bayesian', 0.005), ('mixture', 0.004), ('sample', 0.004), ('density', 0.004), ('approximation', 0.004), ('training', 0.004), ('vector', 0.004), ('step', 0.004), ('likelihood', 0.004), ('class', 0.003), ('structure', 0.003), ('variance', 0.003), ('component', 0.003)]\n",
      "\n",
      "Topic #2:\n",
      "[('class', 0.007), ('training', 0.007), ('size', 0.006), ('vector', 0.005), ('bound', 0.005), ('let', 0.005), ('linear', 0.004), ('node', 0.004), ('probability', 0.004), ('threshold', 0.004), ('theorem', 0.004), ('unit', 0.004), ('complexity', 0.003), ('theory', 0.003), ('distribution', 0.003), ('solution', 0.003), ('machine', 0.003), ('training_set', 0.003), ('consider', 0.003), ('sample', 0.003)]\n",
      "\n",
      "Topic #3:\n",
      "[('equation', 0.01), ('state', 0.009), ('dynamic', 0.008), ('matrix', 0.006), ('vector', 0.006), ('rate', 0.006), ('convergence', 0.006), ('neuron', 0.005), ('solution', 0.005), ('noise', 0.004), ('gradient', 0.004), ('optimal', 0.004), ('eq', 0.004), ('fixed_point', 0.004), ('constant', 0.003), ('stochastic', 0.003), ('let', 0.003), ('theory', 0.003), ('step', 0.003), ('approximation', 0.003)]\n",
      "\n",
      "Topic #4:\n",
      "[('cell', 0.015), ('stimulus', 0.008), ('pattern', 0.008), ('unit', 0.008), ('visual', 0.008), ('response', 0.007), ('activity', 0.007), ('neuron', 0.006), ('map', 0.006), ('motion', 0.005), ('layer', 0.005), ('object', 0.004), ('cortical', 0.004), ('feature', 0.004), ('spatial', 0.004), ('representation', 0.004), ('direction', 0.004), ('cortex', 0.004), ('connection', 0.004), ('orientation', 0.004)]\n",
      "\n",
      "Topic #5:\n",
      "[('image', 0.033), ('unit', 0.013), ('object', 0.009), ('feature', 0.007), ('layer', 0.007), ('pixel', 0.007), ('vector', 0.006), ('local', 0.005), ('linear', 0.004), ('view', 0.004), ('pattern', 0.004), ('shape', 0.004), ('filter', 0.004), ('representation', 0.003), ('region', 0.003), ('surface', 0.003), ('constraint', 0.003), ('transformation', 0.003), ('gaussian', 0.003), ('scale', 0.003)]\n",
      "\n",
      "Topic #6:\n",
      "[('neuron', 0.024), ('circuit', 0.01), ('current', 0.008), ('chip', 0.008), ('signal', 0.007), ('spike', 0.007), ('voltage', 0.006), ('cell', 0.006), ('neural', 0.005), ('frequency', 0.005), ('response', 0.005), ('analog', 0.005), ('synaptic', 0.005), ('channel', 0.004), ('firing', 0.004), ('threshold', 0.004), ('synapse', 0.004), ('connection', 0.003), ('pattern', 0.003), ('synapsis', 0.003)]\n",
      "\n",
      "Topic #7:\n",
      "[('training', 0.009), ('vector', 0.008), ('signal', 0.007), ('control', 0.007), ('linear', 0.006), ('classifier', 0.005), ('nonlinear', 0.005), ('expert', 0.005), ('class', 0.004), ('node', 0.004), ('classification', 0.004), ('architecture', 0.004), ('trajectory', 0.004), ('prediction', 0.004), ('mapping', 0.004), ('adaptive', 0.003), ('dynamic', 0.003), ('sample', 0.003), ('local', 0.003), ('trained', 0.003)]\n",
      "\n",
      "Topic #8:\n",
      "[('training', 0.013), ('word', 0.009), ('unit', 0.009), ('feature', 0.008), ('recognition', 0.008), ('task', 0.006), ('pattern', 0.006), ('trained', 0.006), ('net', 0.005), ('sequence', 0.005), ('representation', 0.005), ('architecture', 0.005), ('node', 0.005), ('layer', 0.005), ('speech', 0.005), ('classifier', 0.004), ('class', 0.004), ('classification', 0.004), ('context', 0.004), ('character', 0.004)]\n",
      "\n",
      "Topic #9:\n",
      "[('state', 0.026), ('action', 0.012), ('control', 0.01), ('policy', 0.007), ('step', 0.007), ('task', 0.006), ('reinforcement_learning', 0.006), ('environment', 0.005), ('optimal', 0.005), ('robot', 0.005), ('controller', 0.004), ('goal', 0.004), ('reward', 0.004), ('machine', 0.003), ('agent', 0.003), ('cost', 0.003), ('current', 0.003), ('trajectory', 0.003), ('trial', 0.003), ('td', 0.003)]\n",
      "\n",
      "Topic #10:\n",
      "[('training', 0.01), ('noise', 0.008), ('pattern', 0.008), ('rule', 0.007), ('ensemble', 0.006), ('unit', 0.005), ('subject', 0.005), ('task', 0.005), ('signal', 0.005), ('test', 0.005), ('prediction', 0.004), ('generalization', 0.004), ('experiment', 0.004), ('target', 0.004), ('trained', 0.004), ('training_set', 0.003), ('response', 0.003), ('ica', 0.003), ('measure', 0.003), ('pruning', 0.003)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt, 3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1666801324068,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "EAkgJa3XRZ3m",
    "outputId": "4ffb9c28-45f2-4c54-e60a-1660e6c57d5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics without Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "['distribution', 'probability', 'state', 'variable', 'estimate', 'prior', 'gaussian', 'bayesian', 'mixture', 'sample', 'density', 'approximation', 'training', 'vector', 'step', 'likelihood', 'class', 'structure', 'variance', 'component']\n",
      "\n",
      "Topic #2:\n",
      "['class', 'training', 'size', 'vector', 'bound', 'let', 'linear', 'node', 'probability', 'threshold', 'theorem', 'unit', 'complexity', 'theory', 'distribution', 'solution', 'machine', 'training_set', 'consider', 'sample']\n",
      "\n",
      "Topic #3:\n",
      "['equation', 'state', 'dynamic', 'matrix', 'vector', 'rate', 'convergence', 'neuron', 'solution', 'noise', 'gradient', 'optimal', 'eq', 'fixed_point', 'constant', 'stochastic', 'let', 'theory', 'step', 'approximation']\n",
      "\n",
      "Topic #4:\n",
      "['cell', 'stimulus', 'pattern', 'unit', 'visual', 'response', 'activity', 'neuron', 'map', 'motion', 'layer', 'object', 'cortical', 'feature', 'spatial', 'representation', 'direction', 'cortex', 'connection', 'orientation']\n",
      "\n",
      "Topic #5:\n",
      "['image', 'unit', 'object', 'feature', 'layer', 'pixel', 'vector', 'local', 'linear', 'view', 'pattern', 'shape', 'filter', 'representation', 'region', 'surface', 'constraint', 'transformation', 'gaussian', 'scale']\n",
      "\n",
      "Topic #6:\n",
      "['neuron', 'circuit', 'current', 'chip', 'signal', 'spike', 'voltage', 'cell', 'neural', 'frequency', 'response', 'analog', 'synaptic', 'channel', 'firing', 'threshold', 'synapse', 'connection', 'pattern', 'synapsis']\n",
      "\n",
      "Topic #7:\n",
      "['training', 'vector', 'signal', 'control', 'linear', 'classifier', 'nonlinear', 'expert', 'class', 'node', 'classification', 'architecture', 'trajectory', 'prediction', 'mapping', 'adaptive', 'dynamic', 'sample', 'local', 'trained']\n",
      "\n",
      "Topic #8:\n",
      "['training', 'word', 'unit', 'feature', 'recognition', 'task', 'pattern', 'trained', 'net', 'sequence', 'representation', 'architecture', 'node', 'layer', 'speech', 'classifier', 'class', 'classification', 'context', 'character']\n",
      "\n",
      "Topic #9:\n",
      "['state', 'action', 'control', 'policy', 'step', 'task', 'reinforcement_learning', 'environment', 'optimal', 'robot', 'controller', 'goal', 'reward', 'machine', 'agent', 'cost', 'current', 'trajectory', 'trial', 'td']\n",
      "\n",
      "Topic #10:\n",
      "['training', 'noise', 'pattern', 'rule', 'ensemble', 'unit', 'subject', 'task', 'signal', 'test', 'prediction', 'generalization', 'experiment', 'target', 'trained', 'training_set', 'response', 'ica', 'measure', 'pruning']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abiy8_Cg12b5"
   },
   "source": [
    "## Evaluating topic model quality\n",
    "\n",
    "We can use perplexity and coherence scores as measures to evaluate the topic\n",
    "model. Typically, lower the perplexity, the better the model. Similarly, the lower the\n",
    "UMass score and the higher the Cv score in coherence, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59201,
     "status": "ok",
     "timestamp": 1666801383267,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "WkOZQdZERbzG",
    "outputId": "36d411f5-1407-44cc-fba4-fbcc46f8b8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.46663554825233095 when it is higher - better model\n",
      "Avg. Coherence Score (UMass): -1.0490426136710163 when it is lower - better model\n",
      "Model Perplexity: -7.795899221122579 the lower the better\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                      texts=norm_corpus_bigrams,\n",
    "                                                      dictionary=dictionary, \n",
    "                                                      coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                         texts=norm_corpus_bigrams,\n",
    "                                                         dictionary=dictionary, \n",
    "                                                         coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
    "\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)\n",
    "\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv, \"when it is higher - better model\")\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass, \"when it is lower - better model\")\n",
    "print('Model Perplexity:', perplexity, \"the lower the better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmuExSjK12b6"
   },
   "source": [
    "# LDA Models with MALLET\n",
    "\n",
    "The MALLET framework is a Java-based package for statistical natural language\n",
    "processing, document classification, clustering, topic modeling, information extraction,\n",
    "and other machine learning applications to text. MALLET stands for MAchine Learning\n",
    "for LanguagE Toolkit. It was developed by Andrew McCallum along with several people\n",
    "at the University of Massachusetts Amherst. The MALLET topic modeling toolkit\n",
    "contains efficient, sampling-based implementations of Latent Dirichlet Allocation,\n",
    "Pachinko Allocation, and Hierarchical LDA. To use MALLET’s capabilities, we need to\n",
    "download the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1666794906089,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "NSRYjYP7VXPz",
    "outputId": "763d91d8-18af-4787-efd2-e6ba556c81d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-26 14:35:05--  http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
      "Resolving mallet.cs.umass.edu (mallet.cs.umass.edu)... 128.119.246.70\n",
      "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://mallet.cs.umass.edu/dist/mallet-2.0.8.zip [following]\n",
      "--2022-10-26 14:35:05--  https://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
      "Connecting to mallet.cs.umass.edu (mallet.cs.umass.edu)|128.119.246.70|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16184794 (15M) [application/zip]\n",
      "Saving to: ‘mallet-2.0.8.zip’\n",
      "\n",
      "mallet-2.0.8.zip    100%[===================>]  15.43M  54.9MB/s    in 0.3s    \n",
      "\n",
      "2022-10-26 14:35:05 (54.9 MB/s) - ‘mallet-2.0.8.zip’ saved [16184794/16184794]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "!unzip -q mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 123067,
     "status": "ok",
     "timestamp": 1666795029155,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "s0J3x_IcVu8z"
   },
   "outputs": [],
   "source": [
    "MALLET_PATH = 'mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus, \n",
    "                                              num_topics=TOTAL_TOPICS, id2word=dictionary,\n",
    "                                              iterations=500, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60028,
     "status": "ok",
     "timestamp": 1666795089180,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "HQcf70_0WHDc",
    "outputId": "96e7f4a6-8419-42be-e9ce-d00aff699688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.520493255305935 when it is higher - better model\n",
      "Avg. Coherence Score (UMass): -1.014793774491642 when it is lower - better model\n",
      "Model Perplexity: -8.52683 the lower the better\n"
     ]
    }
   ],
   "source": [
    "cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                             texts=norm_corpus_bigrams,\n",
    "                                                             dictionary=dictionary, \n",
    "                                                             coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                                texts=norm_corpus_bigrams,\n",
    "                                                                dictionary=dictionary,  \n",
    "                                                                coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "# from STDOUT: <500> LL/token: -8.52683\n",
    "perplexity = -8.52683\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv, \"when it is higher - better model\")\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass, \"when it is lower - better model\")\n",
    "print('Model Perplexity:', perplexity, \"the lower the better\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSL_0ICCMeYm"
   },
   "source": [
    "![](https://i.imgur.com/yAYrq59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvn6Xx9N12cA"
   },
   "source": [
    "# LDA Tuning: Finding the optimal number of topics\n",
    "\n",
    "Finding the optimal number of topics in a topic model is tough, given that it is like a\n",
    "model hyperparameter that you always have to set before training the model. We can\n",
    "use an iterative approach and build several models with differing numbers of topics and\n",
    "select the one that has the highest coherence score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYeyeNmRWy4m"
   },
   "outputs": [],
   "source": [
    "def topic_model_coherence_generator(corpus, texts, dictionary, \n",
    "                                    start_topic_count=2, end_topic_count=10, step=1,\n",
    "                                    cpus=1):\n",
    "    \n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm.tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=corpus,\n",
    "                                                            num_topics=topic_nums, id2word=dictionary,\n",
    "                                                            iterations=500, workers=cpus)\n",
    "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, corpus=corpus, \n",
    "                                                                     texts=texts, dictionary=dictionary, \n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(mallet_lda_model)\n",
    "    \n",
    "    return models, coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "8vgKu5RCXHrv",
    "outputId": "bbcf4798-8ff6-4750-f27a-467f59786259"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/29 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "100%|██████████| 29/29 [1:35:47<00:00, 198.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# DON't RUN LIVE! Takes a lot of time!!! \n",
    "lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, texts=norm_corpus_bigrams,\n",
    "                                                               dictionary=dictionary, start_topic_count=2,\n",
    "                                                               end_topic_count=30, step=1, cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "EeQIjHsOXPvY",
    "outputId": "b865b9f5-7be1-4e44-d14b-34809e9f2645"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.5425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>0.5404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.5367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.5366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.5353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.5342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>0.5340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.5327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Topics  Coherence Score\n",
       "13                15           0.5492\n",
       "18                20           0.5425\n",
       "25                27           0.5404\n",
       "24                26           0.5367\n",
       "20                22           0.5366\n",
       "21                23           0.5365\n",
       "19                21           0.5353\n",
       "15                17           0.5342\n",
       "27                29           0.5340\n",
       "17                19           0.5327"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1),\n",
    "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
    "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "UBSRO_VqYjif",
    "outputId": "56d48181-4df7-4ea1-cbcb-682ab9460fd6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "x_ax = range(2, 31, 1)\n",
    "y_ax = coherence_scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_ax, y_ax, c='r')\n",
    "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "xl = plt.xlabel('Number of Topics')\n",
    "yl = plt.ylabel('Coherence Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7PlAhgx12cI"
   },
   "source": [
    "We choose the optimal number of topics as 15, based on our intuition. We can retrieve the best model now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YtPwVFdrYlxO",
    "outputId": "9a9938ef-b031-454a-8033-da7ce972bd30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 15].index[0]\n",
    "best_lda_model = lda_models[best_model_idx]\n",
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 125174,
     "status": "ok",
     "timestamp": 1666801508439,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "krcnLTbWNCBY"
   },
   "outputs": [],
   "source": [
    "best_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus, \n",
    "                                              num_topics=15, id2word=dictionary,\n",
    "                                              iterations=500, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1666801508439,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "F2O-Uyy5NsLW",
    "outputId": "c3e2b0f8-7afb-4a46-c750-f85be21758c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1666801508439,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "AKh2vVkMNvwT",
    "outputId": "83004be8-db5c-4a5d-b433-7da94e91335a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['state', 'control', 'action', 'trajectory', 'step', 'policy', 'environment', 'controller', 'reinforcement_learning', 'optimal', 'robot', 'task', 'goal', 'dynamic', 'position', 'change', 'path', 'reward', 'movement', 'forward']\n",
      "\n",
      "Topic #2:\n",
      "['task', 'search', 'training', 'experiment', 'target', 'table', 'random', 'run', 'technique', 'test', 'region', 'expert', 'domain', 'trained', 'found', 'average', 'study', 'evaluation', 'good', 'important']\n",
      "\n",
      "Topic #3:\n",
      "['circuit', 'chip', 'current', 'neuron', 'analog', 'bit', 'voltage', 'signal', 'implementation', 'processor', 'design', 'neural', 'operation', 'computation', 'parallel', 'device', 'array', 'synapse', 'digital', 'element']\n",
      "\n",
      "Topic #4:\n",
      "['bound', 'class', 'theorem', 'probability', 'approximation', 'size', 'threshold', 'defined', 'theory', 'proof', 'polynomial', 'linear', 'xi', 'define', 'assume', 'definition', 'complexity', 'condition', 'property', 'constant']\n",
      "\n",
      "Topic #5:\n",
      "['noise', 'prediction', 'rate', 'gradient', 'linear', 'nonlinear', 'step', 'signal', 'optimal', 'adaptive', 'convergence', 'time_series', 'change', 'average', 'line', 'estimate', 'variable', 'noisy', 'stochastic', 'note']\n",
      "\n",
      "Topic #6:\n",
      "['word', 'sequence', 'speech', 'recognition', 'training', 'context', 'state', 'hmm', 'frame', 'mlp', 'speaker', 'signal', 'letter', 'speech_recognition', 'phoneme', 'sound', 'experiment', 'acoustic', 'trained', 'vowel']\n",
      "\n",
      "Topic #7:\n",
      "['distribution', 'gaussian', 'probability', 'prior', 'variable', 'mixture', 'density', 'bayesian', 'component', 'approximation', 'estimate', 'sample', 'likelihood', 'log', 'estimation', 'source', 'variance', 'em', 'posterior', 'equation']\n",
      "\n",
      "Topic #8:\n",
      "['dynamic', 'equation', 'state', 'neuron', 'pattern', 'memory', 'rule', 'correlation', 'eq', 'solution', 'attractor', 'fixed_point', 'capacity', 'theory', 'phase', 'stable', 'fig', 'hopfield', 'field', 'matrix']\n",
      "\n",
      "Topic #9:\n",
      "['cell', 'neuron', 'response', 'activity', 'stimulus', 'spike', 'signal', 'pattern', 'synaptic', 'frequency', 'firing', 'cortical', 'neural', 'effect', 'et_al', 'brain', 'cortex', 'connection', 'synapsis', 'mechanism']\n",
      "\n",
      "Topic #10:\n",
      "['vector', 'matrix', 'constraint', 'solution', 'local', 'cluster', 'linear', 'distance', 'dimensional', 'map', 'transformation', 'code', 'mapping', 'clustering', 'optimization', 'surface', 'technique', 'dimension', 'nonlinear', 'find']\n",
      "\n",
      "Topic #11:\n",
      "['unit', 'layer', 'net', 'hidden_unit', 'pattern', 'architecture', 'training', 'activation', 'recurrent', 'connection', 'back_propagation', 'module', 'trained', 'hidden_layer', 'node', 'hidden', 'task', 'step', 'learn', 'sequence']\n",
      "\n",
      "Topic #12:\n",
      "['training', 'kernel', 'training_set', 'regression', 'optimal', 'estimate', 'test', 'average', 'machine', 'generalization', 'loss', 'ensemble', 'bias', 'generalization_error', 'curve', 'size', 'variance', 'linear', 'selection', 'distribution']\n",
      "\n",
      "Topic #13:\n",
      "['feature', 'class', 'classification', 'classifier', 'pattern', 'image', 'training', 'recognition', 'face', 'character', 'test', 'database', 'sample', 'training_set', 'digit', 'rbf', 'trained', 'error_rate', 'accuracy', 'nearest_neighbor']\n",
      "\n",
      "Topic #14:\n",
      "['rule', 'representation', 'node', 'structure', 'level', 'tree', 'memory', 'graph', 'similarity', 'part', 'group', 'symbol', 'feature', 'language', 'instance', 'represented', 'role', 'connectionist', 'represent', 'theory']\n",
      "\n",
      "Topic #15:\n",
      "['image', 'object', 'visual', 'motion', 'map', 'location', 'direction', 'field', 'receptive_field', 'orientation', 'region', 'position', 'filter', 'spatial', 'feature', 'response', 'view', 'eye', 'pixel', 'local']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = [[(term, round(wt, 3)) \n",
    "               for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
    "                   for n in range(0, best_lda_model.num_topics)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mxtpl5Co12cL"
   },
   "source": [
    "# Viewing LDA Model topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1666796231716,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "K3yf_xhqN0tH",
    "outputId": "24d34da4-d937-4419-afc9-805a815652df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8ed32160-84bb-44af-bc16-9653dde2d71a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Term1</th>\n",
       "      <td>cell</td>\n",
       "      <td>distribution</td>\n",
       "      <td>class</td>\n",
       "      <td>pattern</td>\n",
       "      <td>image</td>\n",
       "      <td>training</td>\n",
       "      <td>word</td>\n",
       "      <td>control</td>\n",
       "      <td>circuit</td>\n",
       "      <td>unit</td>\n",
       "      <td>neuron</td>\n",
       "      <td>rule</td>\n",
       "      <td>vector</td>\n",
       "      <td>state</td>\n",
       "      <td>equation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term2</th>\n",
       "      <td>response</td>\n",
       "      <td>probability</td>\n",
       "      <td>bound</td>\n",
       "      <td>memory</td>\n",
       "      <td>object</td>\n",
       "      <td>prediction</td>\n",
       "      <td>classifier</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>chip</td>\n",
       "      <td>node</td>\n",
       "      <td>signal</td>\n",
       "      <td>task</td>\n",
       "      <td>distance</td>\n",
       "      <td>action</td>\n",
       "      <td>dynamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term3</th>\n",
       "      <td>visual</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>theorem</td>\n",
       "      <td>representation</td>\n",
       "      <td>feature</td>\n",
       "      <td>noise</td>\n",
       "      <td>classification</td>\n",
       "      <td>position</td>\n",
       "      <td>neuron</td>\n",
       "      <td>layer</td>\n",
       "      <td>cell</td>\n",
       "      <td>search</td>\n",
       "      <td>local</td>\n",
       "      <td>step</td>\n",
       "      <td>solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term4</th>\n",
       "      <td>motion</td>\n",
       "      <td>variable</td>\n",
       "      <td>size</td>\n",
       "      <td>target</td>\n",
       "      <td>pixel</td>\n",
       "      <td>training_set</td>\n",
       "      <td>training</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>current</td>\n",
       "      <td>hidden_unit</td>\n",
       "      <td>spike</td>\n",
       "      <td>table</td>\n",
       "      <td>cluster</td>\n",
       "      <td>policy</td>\n",
       "      <td>matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term5</th>\n",
       "      <td>unit</td>\n",
       "      <td>prior</td>\n",
       "      <td>linear</td>\n",
       "      <td>subject</td>\n",
       "      <td>view</td>\n",
       "      <td>average</td>\n",
       "      <td>class</td>\n",
       "      <td>controller</td>\n",
       "      <td>analog</td>\n",
       "      <td>net</td>\n",
       "      <td>frequency</td>\n",
       "      <td>experiment</td>\n",
       "      <td>matrix</td>\n",
       "      <td>reinforcement_learning</td>\n",
       "      <td>vector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term6</th>\n",
       "      <td>stimulus</td>\n",
       "      <td>density</td>\n",
       "      <td>threshold</td>\n",
       "      <td>task</td>\n",
       "      <td>face</td>\n",
       "      <td>kernel</td>\n",
       "      <td>recognition</td>\n",
       "      <td>movement</td>\n",
       "      <td>voltage</td>\n",
       "      <td>activation</td>\n",
       "      <td>response</td>\n",
       "      <td>test</td>\n",
       "      <td>solution</td>\n",
       "      <td>transition</td>\n",
       "      <td>eq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term7</th>\n",
       "      <td>map</td>\n",
       "      <td>mixture</td>\n",
       "      <td>theory</td>\n",
       "      <td>human</td>\n",
       "      <td>filter</td>\n",
       "      <td>estimate</td>\n",
       "      <td>speech</td>\n",
       "      <td>motor</td>\n",
       "      <td>bit</td>\n",
       "      <td>architecture</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>instance</td>\n",
       "      <td>code</td>\n",
       "      <td>optimal</td>\n",
       "      <td>convergence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term8</th>\n",
       "      <td>layer</td>\n",
       "      <td>estimate</td>\n",
       "      <td>approximation</td>\n",
       "      <td>structure</td>\n",
       "      <td>representation</td>\n",
       "      <td>regression</td>\n",
       "      <td>feature</td>\n",
       "      <td>signal</td>\n",
       "      <td>signal</td>\n",
       "      <td>training</td>\n",
       "      <td>activity</td>\n",
       "      <td>feature</td>\n",
       "      <td>map</td>\n",
       "      <td>environment</td>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term9</th>\n",
       "      <td>receptive_field</td>\n",
       "      <td>bayesian</td>\n",
       "      <td>loss</td>\n",
       "      <td>capacity</td>\n",
       "      <td>region</td>\n",
       "      <td>linear</td>\n",
       "      <td>pattern</td>\n",
       "      <td>robot</td>\n",
       "      <td>implementation</td>\n",
       "      <td>pattern</td>\n",
       "      <td>firing</td>\n",
       "      <td>domain</td>\n",
       "      <td>dimension</td>\n",
       "      <td>sequence</td>\n",
       "      <td>gradient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term10</th>\n",
       "      <td>spatial</td>\n",
       "      <td>approximation</td>\n",
       "      <td>probability</td>\n",
       "      <td>effect</td>\n",
       "      <td>surface</td>\n",
       "      <td>test</td>\n",
       "      <td>trained</td>\n",
       "      <td>hand</td>\n",
       "      <td>processor</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>channel</td>\n",
       "      <td>technique</td>\n",
       "      <td>structure</td>\n",
       "      <td>task</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term11</th>\n",
       "      <td>direction</td>\n",
       "      <td>sample</td>\n",
       "      <td>xi</td>\n",
       "      <td>component</td>\n",
       "      <td>shape</td>\n",
       "      <td>optimal</td>\n",
       "      <td>character</td>\n",
       "      <td>target</td>\n",
       "      <td>design</td>\n",
       "      <td>connection</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>machine</td>\n",
       "      <td>feature</td>\n",
       "      <td>control</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term12</th>\n",
       "      <td>activity</td>\n",
       "      <td>component</td>\n",
       "      <td>proof</td>\n",
       "      <td>similarity</td>\n",
       "      <td>scale</td>\n",
       "      <td>variance</td>\n",
       "      <td>hmm</td>\n",
       "      <td>forward</td>\n",
       "      <td>neural</td>\n",
       "      <td>sequence</td>\n",
       "      <td>neural</td>\n",
       "      <td>training</td>\n",
       "      <td>mapping</td>\n",
       "      <td>current</td>\n",
       "      <td>rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term13</th>\n",
       "      <td>eye</td>\n",
       "      <td>log</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>level</td>\n",
       "      <td>part</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>sequence</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>operation</td>\n",
       "      <td>back_propagation</td>\n",
       "      <td>noise</td>\n",
       "      <td>application</td>\n",
       "      <td>graph</td>\n",
       "      <td>path</td>\n",
       "      <td>theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term14</th>\n",
       "      <td>orientation</td>\n",
       "      <td>likelihood</td>\n",
       "      <td>complexity</td>\n",
       "      <td>study</td>\n",
       "      <td>edge</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>context</td>\n",
       "      <td>change</td>\n",
       "      <td>computation</td>\n",
       "      <td>trained</td>\n",
       "      <td>delay</td>\n",
       "      <td>user</td>\n",
       "      <td>clustering</td>\n",
       "      <td>reward</td>\n",
       "      <td>fixed_point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term15</th>\n",
       "      <td>cortical</td>\n",
       "      <td>source</td>\n",
       "      <td>defined</td>\n",
       "      <td>location</td>\n",
       "      <td>visual</td>\n",
       "      <td>generalization</td>\n",
       "      <td>mlp</td>\n",
       "      <td>feedback</td>\n",
       "      <td>parallel</td>\n",
       "      <td>hidden_layer</td>\n",
       "      <td>temporal</td>\n",
       "      <td>query</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>stochastic</td>\n",
       "      <td>attractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term16</th>\n",
       "      <td>center</td>\n",
       "      <td>estimation</td>\n",
       "      <td>assume</td>\n",
       "      <td>trial</td>\n",
       "      <td>location</td>\n",
       "      <td>sample</td>\n",
       "      <td>error_rate</td>\n",
       "      <td>task</td>\n",
       "      <td>device</td>\n",
       "      <td>structure</td>\n",
       "      <td>synapsis</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>representation</td>\n",
       "      <td>td</td>\n",
       "      <td>constraint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term17</th>\n",
       "      <td>pattern</td>\n",
       "      <td>em</td>\n",
       "      <td>define</td>\n",
       "      <td>theory</td>\n",
       "      <td>contour</td>\n",
       "      <td>procedure</td>\n",
       "      <td>speaker</td>\n",
       "      <td>sensor</td>\n",
       "      <td>array</td>\n",
       "      <td>representation</td>\n",
       "      <td>phase</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>linear</td>\n",
       "      <td>goal</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term18</th>\n",
       "      <td>contrast</td>\n",
       "      <td>posterior</td>\n",
       "      <td>distribution</td>\n",
       "      <td>cue</td>\n",
       "      <td>recognition</td>\n",
       "      <td>generalization_error</td>\n",
       "      <td>experiment</td>\n",
       "      <td>arm</td>\n",
       "      <td>digital</td>\n",
       "      <td>connectionist</td>\n",
       "      <td>effect</td>\n",
       "      <td>measure</td>\n",
       "      <td>cost</td>\n",
       "      <td>trial</td>\n",
       "      <td>limit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term19</th>\n",
       "      <td>neuron</td>\n",
       "      <td>entropy</td>\n",
       "      <td>definition</td>\n",
       "      <td>activity</td>\n",
       "      <td>transformation</td>\n",
       "      <td>effect</td>\n",
       "      <td>letter</td>\n",
       "      <td>architecture</td>\n",
       "      <td>connection</td>\n",
       "      <td>hidden</td>\n",
       "      <td>rate</td>\n",
       "      <td>type</td>\n",
       "      <td>basis</td>\n",
       "      <td>agent</td>\n",
       "      <td>neuron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term20</th>\n",
       "      <td>cortex</td>\n",
       "      <td>variance</td>\n",
       "      <td>machine</td>\n",
       "      <td>brain</td>\n",
       "      <td>position</td>\n",
       "      <td>bias</td>\n",
       "      <td>frame</td>\n",
       "      <td>mapping</td>\n",
       "      <td>element</td>\n",
       "      <td>symbol</td>\n",
       "      <td>threshold</td>\n",
       "      <td>run</td>\n",
       "      <td>technique</td>\n",
       "      <td>probability</td>\n",
       "      <td>eigenvalue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ed32160-84bb-44af-bc16-9653dde2d71a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8ed32160-84bb-44af-bc16-9653dde2d71a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8ed32160-84bb-44af-bc16-9653dde2d71a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                Topic 1        Topic 2        Topic 3         Topic 4  \\\n",
       "Term1              cell   distribution          class         pattern   \n",
       "Term2          response    probability          bound          memory   \n",
       "Term3            visual       gaussian        theorem  representation   \n",
       "Term4            motion       variable           size          target   \n",
       "Term5              unit          prior         linear         subject   \n",
       "Term6          stimulus        density      threshold            task   \n",
       "Term7               map        mixture         theory           human   \n",
       "Term8             layer       estimate  approximation       structure   \n",
       "Term9   receptive_field       bayesian           loss        capacity   \n",
       "Term10          spatial  approximation    probability          effect   \n",
       "Term11        direction         sample             xi       component   \n",
       "Term12         activity      component          proof      similarity   \n",
       "Term13              eye            log     polynomial           level   \n",
       "Term14      orientation     likelihood     complexity           study   \n",
       "Term15         cortical         source        defined        location   \n",
       "Term16           center     estimation         assume           trial   \n",
       "Term17          pattern             em         define          theory   \n",
       "Term18         contrast      posterior   distribution             cue   \n",
       "Term19           neuron        entropy     definition        activity   \n",
       "Term20           cortex       variance        machine           brain   \n",
       "\n",
       "               Topic 5               Topic 6         Topic 7       Topic 8  \\\n",
       "Term1            image              training            word       control   \n",
       "Term2           object            prediction      classifier    trajectory   \n",
       "Term3          feature                 noise  classification      position   \n",
       "Term4            pixel          training_set        training       dynamic   \n",
       "Term5             view               average           class    controller   \n",
       "Term6             face                kernel     recognition      movement   \n",
       "Term7           filter              estimate          speech         motor   \n",
       "Term8   representation            regression         feature        signal   \n",
       "Term9           region                linear         pattern         robot   \n",
       "Term10         surface                  test         trained          hand   \n",
       "Term11           shape               optimal       character        target   \n",
       "Term12           scale              variance             hmm       forward   \n",
       "Term13            part             nonlinear        sequence      adaptive   \n",
       "Term14            edge              ensemble         context        change   \n",
       "Term15          visual        generalization             mlp      feedback   \n",
       "Term16        location                sample      error_rate          task   \n",
       "Term17         contour             procedure         speaker        sensor   \n",
       "Term18     recognition  generalization_error      experiment           arm   \n",
       "Term19  transformation                effect          letter  architecture   \n",
       "Term20        position                  bias           frame       mapping   \n",
       "\n",
       "               Topic 9          Topic 10   Topic 11     Topic 12  \\\n",
       "Term1          circuit              unit     neuron         rule   \n",
       "Term2             chip              node     signal         task   \n",
       "Term3           neuron             layer       cell       search   \n",
       "Term4          current       hidden_unit      spike        table   \n",
       "Term5           analog               net  frequency   experiment   \n",
       "Term6          voltage        activation   response         test   \n",
       "Term7              bit      architecture   synaptic     instance   \n",
       "Term8           signal          training   activity      feature   \n",
       "Term9   implementation           pattern     firing       domain   \n",
       "Term10       processor         recurrent    channel    technique   \n",
       "Term11          design        connection   stimulus      machine   \n",
       "Term12          neural          sequence     neural     training   \n",
       "Term13       operation  back_propagation      noise  application   \n",
       "Term14     computation           trained      delay         user   \n",
       "Term15        parallel      hidden_layer   temporal        query   \n",
       "Term16          device         structure   synapsis     accuracy   \n",
       "Term17           array    representation      phase    knowledge   \n",
       "Term18         digital     connectionist     effect      measure   \n",
       "Term19      connection            hidden       rate         type   \n",
       "Term20         element            symbol  threshold          run   \n",
       "\n",
       "              Topic 13                Topic 14     Topic 15  \n",
       "Term1           vector                   state     equation  \n",
       "Term2         distance                  action      dynamic  \n",
       "Term3            local                    step     solution  \n",
       "Term4          cluster                  policy       matrix  \n",
       "Term5           matrix  reinforcement_learning       vector  \n",
       "Term6         solution              transition           eq  \n",
       "Term7             code                 optimal  convergence  \n",
       "Term8              map             environment         rate  \n",
       "Term9        dimension                sequence     gradient  \n",
       "Term10       structure                    task       energy  \n",
       "Term11         feature                 control        state  \n",
       "Term12         mapping                 current         rule  \n",
       "Term13           graph                    path       theory  \n",
       "Term14      clustering                  reward  fixed_point  \n",
       "Term15     dimensional              stochastic    attractor  \n",
       "Term16  representation                      td   constraint  \n",
       "Term17          linear                    goal         line  \n",
       "Term18            cost                   trial        limit  \n",
       "Term19           basis                   agent       neuron  \n",
       "Term20       technique             probability   eigenvalue  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
    "                              for topic in topics], \n",
    "                         columns = ['Term'+str(i) for i in range(1, 21)],\n",
    "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1666796234101,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "MvyOKlu4p7UG",
    "outputId": "2a304a59-67fc-4fb8-9971-98c6a44a14e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-22b2eeb1-1654-4b5f-8180-0e48b809d364\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>cell, response, visual, motion, unit, stimulus, map, layer, receptive_field, spatial, direction, activity, eye, orientation, cortical, center, pattern, contrast, neuron, cortex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>distribution, probability, gaussian, variable, prior, density, mixture, estimate, bayesian, approximation, sample, component, log, likelihood, source, estimation, em, posterior, entropy, variance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>class, bound, theorem, size, linear, threshold, theory, approximation, loss, probability, xi, proof, polynomial, complexity, defined, assume, define, distribution, definition, machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>pattern, memory, representation, target, subject, task, human, structure, capacity, effect, component, similarity, level, study, location, trial, theory, cue, activity, brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>image, object, feature, pixel, view, face, filter, representation, region, surface, shape, scale, part, edge, visual, location, contour, recognition, transformation, position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>training, prediction, noise, training_set, average, kernel, estimate, regression, linear, test, optimal, variance, nonlinear, ensemble, generalization, sample, procedure, generalization_error, effect, bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>word, classifier, classification, training, class, recognition, speech, feature, pattern, trained, character, hmm, sequence, context, mlp, error_rate, speaker, experiment, letter, frame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>control, trajectory, position, dynamic, controller, movement, motor, signal, robot, hand, target, forward, adaptive, change, feedback, task, sensor, arm, architecture, mapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>circuit, chip, neuron, current, analog, voltage, bit, signal, implementation, processor, design, neural, operation, computation, parallel, device, array, digital, connection, element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>unit, node, layer, hidden_unit, net, activation, architecture, training, pattern, recurrent, connection, sequence, back_propagation, trained, hidden_layer, structure, representation, connectionist, hidden, symbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>neuron, signal, cell, spike, frequency, response, synaptic, activity, firing, channel, stimulus, neural, noise, delay, temporal, synapsis, phase, effect, rate, threshold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>rule, task, search, table, experiment, test, instance, feature, domain, technique, machine, training, application, user, query, accuracy, knowledge, measure, type, run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>vector, distance, local, cluster, matrix, solution, code, map, dimension, structure, feature, mapping, graph, clustering, dimensional, representation, linear, cost, basis, technique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>state, action, step, policy, reinforcement_learning, transition, optimal, environment, sequence, task, control, current, path, reward, stochastic, td, goal, trial, agent, probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>equation, dynamic, solution, matrix, vector, eq, convergence, rate, gradient, energy, state, rule, theory, fixed_point, attractor, constraint, line, limit, neuron, eigenvalue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22b2eeb1-1654-4b5f-8180-0e48b809d364')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-22b2eeb1-1654-4b5f-8180-0e48b809d364 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-22b2eeb1-1654-4b5f-8180-0e48b809d364');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                                                                                                                                                                              Terms per Topic\n",
       "Topic1   cell, response, visual, motion, unit, stimulus, map, layer, receptive_field, spatial, direction, activity, eye, orientation, cortical, center, pattern, contrast, neuron, cortex                                    \n",
       "Topic2   distribution, probability, gaussian, variable, prior, density, mixture, estimate, bayesian, approximation, sample, component, log, likelihood, source, estimation, em, posterior, entropy, variance                 \n",
       "Topic3   class, bound, theorem, size, linear, threshold, theory, approximation, loss, probability, xi, proof, polynomial, complexity, defined, assume, define, distribution, definition, machine                             \n",
       "Topic4   pattern, memory, representation, target, subject, task, human, structure, capacity, effect, component, similarity, level, study, location, trial, theory, cue, activity, brain                                      \n",
       "Topic5   image, object, feature, pixel, view, face, filter, representation, region, surface, shape, scale, part, edge, visual, location, contour, recognition, transformation, position                                      \n",
       "Topic6   training, prediction, noise, training_set, average, kernel, estimate, regression, linear, test, optimal, variance, nonlinear, ensemble, generalization, sample, procedure, generalization_error, effect, bias       \n",
       "Topic7   word, classifier, classification, training, class, recognition, speech, feature, pattern, trained, character, hmm, sequence, context, mlp, error_rate, speaker, experiment, letter, frame                           \n",
       "Topic8   control, trajectory, position, dynamic, controller, movement, motor, signal, robot, hand, target, forward, adaptive, change, feedback, task, sensor, arm, architecture, mapping                                     \n",
       "Topic9   circuit, chip, neuron, current, analog, voltage, bit, signal, implementation, processor, design, neural, operation, computation, parallel, device, array, digital, connection, element                              \n",
       "Topic10  unit, node, layer, hidden_unit, net, activation, architecture, training, pattern, recurrent, connection, sequence, back_propagation, trained, hidden_layer, structure, representation, connectionist, hidden, symbol\n",
       "Topic11  neuron, signal, cell, spike, frequency, response, synaptic, activity, firing, channel, stimulus, neural, noise, delay, temporal, synapsis, phase, effect, rate, threshold                                           \n",
       "Topic12  rule, task, search, table, experiment, test, instance, feature, domain, technique, machine, training, application, user, query, accuracy, knowledge, measure, type, run                                             \n",
       "Topic13  vector, distance, local, cluster, matrix, solution, code, map, dimension, structure, feature, mapping, graph, clustering, dimensional, representation, linear, cost, basis, technique                               \n",
       "Topic14  state, action, step, policy, reinforcement_learning, transition, optimal, environment, sequence, task, control, current, path, reward, stochastic, td, goal, trial, agent, probability                              \n",
       "Topic15  equation, dynamic, solution, matrix, vector, eq, convergence, rate, gradient, energy, state, rule, theory, fixed_point, attractor, constraint, line, limit, neuron, eigenvalue                                      "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic])  \n",
    "                              for topic in topics],\n",
    "                         columns = ['Terms per Topic'],\n",
    "                         index=['Topic'+str(t) for t in range(1, best_lda_model.num_topics+1)]\n",
    "                         )\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrveLQ5e12cP"
   },
   "source": [
    "# Interpreting Topic Model Results\n",
    "\n",
    "An interesting point to remember is, given a corpus of documents (in the form of\n",
    "features, e.g., Bag of Words) and a trained topic model, you can predict the distribution of\n",
    "topics in each document (research paper in this case).\n",
    "\n",
    "We can now get the most dominant topic per research paper with some intelligent\n",
    "sorting and indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1666796236797,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "xYz9Pf4UN_VJ",
    "outputId": "fe4d1237-10ff-4427-c761-c6e6bd73fa68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 2), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(bow_corpus[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666796239044,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "ojE7cAX7ORuS",
    "outputId": "947fe849-91bf-471b-ac39-6f7562141c47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2m', 1), ('2r', 1), ('3a', 1), ('4a', 1), ('4b', 1), ('4c', 1), ('ability', 1), ('ac', 2), ('acad_sci', 1), ('according', 1), ('acknowledgement', 1), ('add', 1), ('adding', 2), ('addition', 2), ('additional', 1), ('advance', 1), ('affecting', 1), ('ai', 1), ('allow', 1), ('almost', 2), ('although', 1), ('always', 1), ('american_institute', 1), ('among', 1), ('analyzed', 1), ('another', 1), ('ap', 1), ('appear', 1), ('appears', 1), ('applicable', 1)]\n"
     ]
    }
   ],
   "source": [
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[0][:30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 21238,
     "status": "ok",
     "timestamp": 1666796260706,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "bXv0NRCXum-I"
   },
   "outputs": [],
   "source": [
    "tm_results = best_lda_model[bow_corpus] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1666796260708,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "g0pWhZX1OeHf",
    "outputId": "1230fe09-b331-4ddd-983f-5036e2fed2fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.017356475300400534),\n",
       " (1, 0.029075804776739357),\n",
       " (2, 0.1754932502596054),\n",
       " (3, 0.11096276516837265),\n",
       " (4, 0.025070464322800773),\n",
       " (5, 0.010087524106215698),\n",
       " (6, 0.007268951194184841),\n",
       " (7, 0.04776739356178609),\n",
       " (8, 0.12327547841566536),\n",
       " (9, 0.03322949117341642),\n",
       " (10, 0.022251891410769917),\n",
       " (11, 0.026108885921970033),\n",
       " (12, 0.06200860406467883),\n",
       " (13, 0.018988280670523657),\n",
       " (14, 0.2910547396528705)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1666796260709,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "WjEHWhVGuuG5",
    "outputId": "52c799b5-50c3-4e02-d4d9-24817a735470"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(14, 0.2910547396528705),\n",
       " (14, 0.2867063492063492),\n",
       " (3, 0.27108585858585854),\n",
       " (10, 0.3829275623685002),\n",
       " (10, 0.6344153141905952)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] \n",
    "                     for topics in tm_results]\n",
    "corpus_topics[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1666796260709,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "GFmddPmQuyXS"
   },
   "outputs": [],
   "source": [
    "corpus_topic_df = pd.DataFrame()\n",
    "corpus_topic_df['Document'] = range(0, len(papers))\n",
    "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
    "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
    "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
    "corpus_topic_df['Paper'] = [paper[:500] for paper in papers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_nNj9_t12cb"
   },
   "source": [
    "# Dominant Topics in Specific Research Papers\n",
    "\n",
    "Another interesting perspective is to select specific papers, view the most dominant topic\n",
    "in each of those papers, and see if that makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1666796260709,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "pN45exiiu5sx",
    "outputId": "a337606e-1b59-4c00-e1a2-706d29694ffa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c970f61c-acec-4e86-8b01-a3566a83912f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1041</td>\n",
       "      <td>1</td>\n",
       "      <td>70.98</td>\n",
       "      <td>cell, response, visual, motion, unit, stimulus, map, layer, receptive_field, spatial, direction, activity, eye, orientation, cortical, center, pattern, contrast, neuron, cortex</td>\n",
       "      <td>A model of transparent motion and \\nnon-transparent motion aftereffects \\nAlexander Grunewald* \\nMax-Planck Institut fiir biologische Kybernetik \\nSpemannstral]e 38 \\nD-72076 Tiibingen, Germany \\nAbstract \\nA model of human motion perception is presented. The model \\ncontains two stages of direction selective units. The first stage con- \\ntains broadly tuned units, while the second stage contains units \\nthat are narrowly tuned. The model accounts for the motion af- \\ntereffect through adapting units at th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1724</td>\n",
       "      <td>2</td>\n",
       "      <td>65.55</td>\n",
       "      <td>distribution, probability, gaussian, variable, prior, density, mixture, estimate, bayesian, approximation, sample, component, log, likelihood, source, estimation, em, posterior, entropy, variance</td>\n",
       "      <td>The Infinite Gaussian Mixture Model \\nCarl Edward Rasmussen \\nDepartment of Mathematical Modelling \\nTechnical University of Denmark \\nBuilding 321, DK-2800 Kongens Lyngby, Denmark \\ncarl@imm.dtu.dk http://bayes.imm.dtu.dk \\nAbstract \\nIn a Bayesian mixture model it is not necessary a priori to limit the num- \\nber of components to be finite. In this paper an infinite Gaussian mixture \\nmodel is presented which neatly sidesteps the difficult problem of find- \\ning the \"right\" number of mixture components.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>522</td>\n",
       "      <td>3</td>\n",
       "      <td>84.16</td>\n",
       "      <td>class, bound, theorem, size, linear, threshold, theory, approximation, loss, probability, xi, proof, polynomial, complexity, defined, assume, define, distribution, definition, machine</td>\n",
       "      <td>Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversitk degli Studi di Milano \\nvia Comelico, 39 - 20135 Milano- Italy \\nAbstract \\nWe define the concept of polynomial uniform convergence of relative \\nfrequencies to probabilities in the distribution-dependent context. Let \\nX = {0, 1} , let P be a probability distribution on X and let F C 2 x' \\nbe a family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>4</td>\n",
       "      <td>60.23</td>\n",
       "      <td>pattern, memory, representation, target, subject, task, human, structure, capacity, effect, component, similarity, level, study, location, trial, theory, cue, activity, brain</td>\n",
       "      <td>Direct memory access using two cues: Finding \\nthe intersection of sets in a connectionist model \\nJanet Wiles, Michael S. Humphreys, John D. Bain and Simon Dennis \\nDepartments of Psychology and Computer Science \\nUniversity of Queensland QLD 4072 Australia \\nemail: j anetCWpsych.psy.uq.oz.au \\nAbstract \\nFor lack of alternative models, search and decision processes have provided the \\ndominant paradigm for human memory access using two or more cues, despite \\nevidence against search as an access proces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>544</td>\n",
       "      <td>5</td>\n",
       "      <td>61.81</td>\n",
       "      <td>image, object, feature, pixel, view, face, filter, representation, region, surface, shape, scale, part, edge, visual, location, contour, recognition, transformation, position</td>\n",
       "      <td>Illumination and View Position in 3D Visual \\nRecognition \\nAmnon Shashua \\nM.I.T. Artificial Intelligence Lab., NE43-737 \\nand Department of Brain and Cognitive Science \\nCambridge, MA 02139 \\nAbstract \\nIt is shown that both changes in viewing position and illumination con- \\nditions can be compensated for, prior to recognition, using combinations \\nof images taken from different viewing positions and different illumina- \\ntion conditions. It is also shown that, in agreement with psychophysical \\nfinding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>976</td>\n",
       "      <td>6</td>\n",
       "      <td>67.38</td>\n",
       "      <td>training, prediction, noise, training_set, average, kernel, estimate, regression, linear, test, optimal, variance, nonlinear, ensemble, generalization, sample, procedure, generalization_error, effect, bias</td>\n",
       "      <td>Neural Network Ensembles, Cross \\nValidation, and Active Learning \\nAnders Krogh* \\nNordita \\nBlegdamsvej 17 \\n2100 Copenhagen, Denmark \\nJesper Vedelsby \\nElectronics Institute, Building 349 \\nTechnical University of Denmark \\n2800 Lyngby, Denmark \\nAbstract \\nLearning of continuous valued functions using neural network en- \\nsembles (committees) can give improved accuracy, reliable estima- \\ntion of the generalization error, and active learning. The ambiguity \\nis defined as the variation of the output of e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>211</td>\n",
       "      <td>7</td>\n",
       "      <td>72.29</td>\n",
       "      <td>word, classifier, classification, training, class, recognition, speech, feature, pattern, trained, character, hmm, sequence, context, mlp, error_rate, speaker, experiment, letter, frame</td>\n",
       "      <td>194 Huang and Lippmann \\nHMM Speech Recognition \\nwith Neural Net Discrimination* \\nWilliam Y. Huang and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nRoom B-349 \\nLexington, MA 02173-9108 \\nABSTRACT \\nTwo approaches were explored which integrate neural net classifiers \\nwith Hidden Markov Model (HMM) speech recognizers. Both at- \\ntempt to improve speech pattern discrimination while retaining the \\ntemporal processing advantages of ltMMs. One approach used neu- \\nral nets to provide second-stage discrimi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>354</td>\n",
       "      <td>8</td>\n",
       "      <td>76.78</td>\n",
       "      <td>control, trajectory, position, dynamic, controller, movement, motor, signal, robot, hand, target, forward, adaptive, change, feedback, task, sensor, arm, architecture, mapping</td>\n",
       "      <td>Learning Trajectory and Force Control \\nof an Artificial Muscle Arm \\nby Parallel-hierarchical Neural Network Model \\nMasazumi Katayama Mitsuo Kawato \\nCognitive Processes Department \\nATR Auditory and Visual Perception Research Laboratories \\nSeika-cho, Soraku-gun, Kyoto 619-02, JAPAN \\nAbstract \\nWe propose a new parallel-hierarchical neural network model to enable motor \\nlearning for simultaneous control of both trajectory and force, by integrating \\nHogan's control method and our previous neural netw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>73.95</td>\n",
       "      <td>circuit, chip, neuron, current, analog, voltage, bit, signal, implementation, processor, design, neural, operation, computation, parallel, device, array, digital, connection, element</td>\n",
       "      <td>564 \\nPROGRAMMABLE SYNAPTIC CHIP FOR \\nELECTRONIC NEURAL NETWORKS \\nA. Moopenn, H. Langenbacher, A.P. Thakoor, and S.K. Khanna \\nJet Propulsion Laboratory \\nCalifornia Institute of Technology \\nPasadena, CA 91009 \\nABSTRACT \\nA binary synaptic matrix chip has been developed for electronic \\nneural networks. The matrix chip contains a programmable 32X32 \\narray of \"long channel\" NMOSFET binary connection elements imple- \\nmented in a 3-um bulk CMOS process. Since the neurons are kept off- \\nchip, the synapti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>688</td>\n",
       "      <td>10</td>\n",
       "      <td>67.83</td>\n",
       "      <td>unit, node, layer, hidden_unit, net, activation, architecture, training, pattern, recurrent, connection, sequence, back_propagation, trained, hidden_layer, structure, representation, connectionist, hidden, symbol</td>\n",
       "      <td>A Connectionist Symbol Manipulator \\nThat Discovers the Structure of \\nContext-Free Languages \\nMichael C. Mozer and Sreerupa Das \\nDepartment of Computer Science &amp; \\nInstitute of Cognitive Science \\nUniversity of Colorado \\nBoulder, CO 80309-0430 \\nAbstract \\nWe present a neural net architecture that can discover hierarchical and re- \\ncursire structure in symbol strings. To detect structure at multiple levels, \\nthe architecture has the capability of reducing symbols substrings to single \\nsymbols, and ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>215</td>\n",
       "      <td>11</td>\n",
       "      <td>76.82</td>\n",
       "      <td>neuron, signal, cell, spike, frequency, response, synaptic, activity, firing, channel, stimulus, neural, noise, delay, temporal, synapsis, phase, effect, rate, threshold</td>\n",
       "      <td>A Systematic Study of the Input/Output Properties 149 \\nA Systematic Study of the Input/Output Properties \\nof a 2 Compartment Model Neuron \\nWith Active Membranes \\nPaul Rhodes \\nUniversity of California, San Diego \\nABSTRACT \\nThe input/output properties of a 2 compartment model neuron are systematically \\nexplored. Taken from the work of MacGregor (MacGregor, 1987), the model neuron \\ncompartments contain several active conductances, including a potassium conductance in \\nthe dendritic compartment driv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>609</td>\n",
       "      <td>12</td>\n",
       "      <td>57.66</td>\n",
       "      <td>rule, task, search, table, experiment, test, instance, feature, domain, technique, machine, training, application, user, query, accuracy, knowledge, measure, type, run</td>\n",
       "      <td>A Knowledge-Based Model of Geometry Learning \\nGeoffrey Towell \\nSiemens Corporate Research \\n755 College Road East \\nPrinceton, NJ 08540 \\ntoweli @ learning. siemens. com \\nRichard Lehrer \\nEducational Psychology \\nUniversity of Wisconsin \\n1025 West Johnson St. \\nMadison, WI 53706 \\nIehrer@vms. macc. wisc. edu \\nAbstract \\nWe propose a model of the development of geometric reasoning in children that \\nexplicitly involves learning. The model uses a neural network that is initialized \\nwith an understanding of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1207</td>\n",
       "      <td>13</td>\n",
       "      <td>53.72</td>\n",
       "      <td>vector, distance, local, cluster, matrix, solution, code, map, dimension, structure, feature, mapping, graph, clustering, dimensional, representation, linear, cost, basis, technique</td>\n",
       "      <td>Limitations of self-organizing maps for \\nvector quantization and multidimensional \\nscaling \\nArthur Flexer \\nThe Austrian Research Institute for Artificial Intelligence \\nSchottengasse 3, A-1010 Vienna, Austria \\nand \\nDepartment of Psychology, University of Vienna \\nLiebiggasse 5, A-1010 Vienna, Austria \\narthur@ai .univie. ac. at \\nAbstract \\nThe limitations of using self-organizing maps (SOM) for either \\nclustering/vector quantization (VQ) or multidimensional scaling \\n(MDS) are being discussed by revi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1262</td>\n",
       "      <td>14</td>\n",
       "      <td>76.68</td>\n",
       "      <td>state, action, step, policy, reinforcement_learning, transition, optimal, environment, sequence, task, control, current, path, reward, stochastic, td, goal, trial, agent, probability</td>\n",
       "      <td>Reinforcement Learning for Mixed \\nOpen-loop and Closed-loop Control \\nEric A. Hansen, Andrew G. Barto, and Shlomo Zilbersteln \\nDepartment of Computer Science \\nUniversity of Massachusetts \\nAmherst, MA 01003 \\nhansen ,barto,shlomo)cs.u mass.edu \\nAbstract \\nClosed-loop control relies on sensory feedback that is usually as- \\nsumed to be free. But if sensing incurs a cost, it may be cost- \\neffective to take sequences of actions in open-loop mode. We de- \\nscribe a reinforcement learning algorithm that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1036</td>\n",
       "      <td>15</td>\n",
       "      <td>63.53</td>\n",
       "      <td>equation, dynamic, solution, matrix, vector, eq, convergence, rate, gradient, energy, state, rule, theory, fixed_point, attractor, constraint, line, limit, neuron, eigenvalue</td>\n",
       "      <td>Dynamics of On-Line Gradient Descent \\nLearning for Multilayer Neural Networks \\nDavid Saad* \\nDept. of Comp. Sci. &amp; App. Math. \\nAston University \\nBirmingham B4 7ET, UK \\nSara A. Solla t \\nCONNECT, The Niels Bohr Institute \\nBlegdamsdvej 17 \\nCopenhagen 2100, Denmark \\nAbstract \\nWe consider the problem of on-line gradient descent learning for \\ngeneral two-layer neural networks. An analytic solution is pre- \\nsented and used to investigate the role of the learning rate in con- \\ntrolling the evolution and</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c970f61c-acec-4e86-8b01-a3566a83912f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c970f61c-acec-4e86-8b01-a3566a83912f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c970f61c-acec-4e86-8b01-a3566a83912f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                Document  Dominant Topic  Contribution %  \\\n",
       "Dominant Topic                                             \n",
       "1               1041      1               70.98            \n",
       "2               1724      2               65.55            \n",
       "3               522       3               84.16            \n",
       "4               314       4               60.23            \n",
       "5               544       5               61.81            \n",
       "6               976       6               67.38            \n",
       "7               211       7               72.29            \n",
       "8               354       8               76.78            \n",
       "9               24        9               73.95            \n",
       "10              688       10              67.83            \n",
       "11              215       11              76.82            \n",
       "12              609       12              57.66            \n",
       "13              1207      13              53.72            \n",
       "14              1262      14              76.68            \n",
       "15              1036      15              63.53            \n",
       "\n",
       "                                                                                                                                                                                                                          Topic Desc  \\\n",
       "Dominant Topic                                                                                                                                                                                                                         \n",
       "1               cell, response, visual, motion, unit, stimulus, map, layer, receptive_field, spatial, direction, activity, eye, orientation, cortical, center, pattern, contrast, neuron, cortex                                       \n",
       "2               distribution, probability, gaussian, variable, prior, density, mixture, estimate, bayesian, approximation, sample, component, log, likelihood, source, estimation, em, posterior, entropy, variance                    \n",
       "3               class, bound, theorem, size, linear, threshold, theory, approximation, loss, probability, xi, proof, polynomial, complexity, defined, assume, define, distribution, definition, machine                                \n",
       "4               pattern, memory, representation, target, subject, task, human, structure, capacity, effect, component, similarity, level, study, location, trial, theory, cue, activity, brain                                         \n",
       "5               image, object, feature, pixel, view, face, filter, representation, region, surface, shape, scale, part, edge, visual, location, contour, recognition, transformation, position                                         \n",
       "6               training, prediction, noise, training_set, average, kernel, estimate, regression, linear, test, optimal, variance, nonlinear, ensemble, generalization, sample, procedure, generalization_error, effect, bias          \n",
       "7               word, classifier, classification, training, class, recognition, speech, feature, pattern, trained, character, hmm, sequence, context, mlp, error_rate, speaker, experiment, letter, frame                              \n",
       "8               control, trajectory, position, dynamic, controller, movement, motor, signal, robot, hand, target, forward, adaptive, change, feedback, task, sensor, arm, architecture, mapping                                        \n",
       "9               circuit, chip, neuron, current, analog, voltage, bit, signal, implementation, processor, design, neural, operation, computation, parallel, device, array, digital, connection, element                                 \n",
       "10              unit, node, layer, hidden_unit, net, activation, architecture, training, pattern, recurrent, connection, sequence, back_propagation, trained, hidden_layer, structure, representation, connectionist, hidden, symbol   \n",
       "11              neuron, signal, cell, spike, frequency, response, synaptic, activity, firing, channel, stimulus, neural, noise, delay, temporal, synapsis, phase, effect, rate, threshold                                              \n",
       "12              rule, task, search, table, experiment, test, instance, feature, domain, technique, machine, training, application, user, query, accuracy, knowledge, measure, type, run                                                \n",
       "13              vector, distance, local, cluster, matrix, solution, code, map, dimension, structure, feature, mapping, graph, clustering, dimensional, representation, linear, cost, basis, technique                                  \n",
       "14              state, action, step, policy, reinforcement_learning, transition, optimal, environment, sequence, task, control, current, path, reward, stochastic, td, goal, trial, agent, probability                                 \n",
       "15              equation, dynamic, solution, matrix, vector, eq, convergence, rate, gradient, energy, state, rule, theory, fixed_point, attractor, constraint, line, limit, neuron, eigenvalue                                         \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Paper  \n",
       "Dominant Topic                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1               A model of transparent motion and \\nnon-transparent motion aftereffects \\nAlexander Grunewald* \\nMax-Planck Institut fiir biologische Kybernetik \\nSpemannstral]e 38 \\nD-72076 Tiibingen, Germany \\nAbstract \\nA model of human motion perception is presented. The model \\ncontains two stages of direction selective units. The first stage con- \\ntains broadly tuned units, while the second stage contains units \\nthat are narrowly tuned. The model accounts for the motion af- \\ntereffect through adapting units at th      \n",
       "2               The Infinite Gaussian Mixture Model \\nCarl Edward Rasmussen \\nDepartment of Mathematical Modelling \\nTechnical University of Denmark \\nBuilding 321, DK-2800 Kongens Lyngby, Denmark \\ncarl@imm.dtu.dk http://bayes.imm.dtu.dk \\nAbstract \\nIn a Bayesian mixture model it is not necessary a priori to limit the num- \\nber of components to be finite. In this paper an infinite Gaussian mixture \\nmodel is presented which neatly sidesteps the difficult problem of find- \\ning the \"right\" number of mixture components.       \n",
       "3               Polynomial Uniform Convergence of \\nRelative Frequencies to Probabilities \\nAlberto Bertoni, Paola Campadelll;' Anna Morpurgo, Sandra Panlzza \\nDipartimento di Scienze dell'Informazione \\nUniversitk degli Studi di Milano \\nvia Comelico, 39 - 20135 Milano- Italy \\nAbstract \\nWe define the concept of polynomial uniform convergence of relative \\nfrequencies to probabilities in the distribution-dependent context. Let \\nX = {0, 1} , let P be a probability distribution on X and let F C 2 x' \\nbe a family        \n",
       "4               Direct memory access using two cues: Finding \\nthe intersection of sets in a connectionist model \\nJanet Wiles, Michael S. Humphreys, John D. Bain and Simon Dennis \\nDepartments of Psychology and Computer Science \\nUniversity of Queensland QLD 4072 Australia \\nemail: j anetCWpsych.psy.uq.oz.au \\nAbstract \\nFor lack of alternative models, search and decision processes have provided the \\ndominant paradigm for human memory access using two or more cues, despite \\nevidence against search as an access proces        \n",
       "5               Illumination and View Position in 3D Visual \\nRecognition \\nAmnon Shashua \\nM.I.T. Artificial Intelligence Lab., NE43-737 \\nand Department of Brain and Cognitive Science \\nCambridge, MA 02139 \\nAbstract \\nIt is shown that both changes in viewing position and illumination con- \\nditions can be compensated for, prior to recognition, using combinations \\nof images taken from different viewing positions and different illumina- \\ntion conditions. It is also shown that, in agreement with psychophysical \\nfinding      \n",
       "6               Neural Network Ensembles, Cross \\nValidation, and Active Learning \\nAnders Krogh* \\nNordita \\nBlegdamsvej 17 \\n2100 Copenhagen, Denmark \\nJesper Vedelsby \\nElectronics Institute, Building 349 \\nTechnical University of Denmark \\n2800 Lyngby, Denmark \\nAbstract \\nLearning of continuous valued functions using neural network en- \\nsembles (committees) can give improved accuracy, reliable estima- \\ntion of the generalization error, and active learning. The ambiguity \\nis defined as the variation of the output of e   \n",
       "7               194 Huang and Lippmann \\nHMM Speech Recognition \\nwith Neural Net Discrimination* \\nWilliam Y. Huang and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nRoom B-349 \\nLexington, MA 02173-9108 \\nABSTRACT \\nTwo approaches were explored which integrate neural net classifiers \\nwith Hidden Markov Model (HMM) speech recognizers. Both at- \\ntempt to improve speech pattern discrimination while retaining the \\ntemporal processing advantages of ltMMs. One approach used neu- \\nral nets to provide second-stage discrimi     \n",
       "8               Learning Trajectory and Force Control \\nof an Artificial Muscle Arm \\nby Parallel-hierarchical Neural Network Model \\nMasazumi Katayama Mitsuo Kawato \\nCognitive Processes Department \\nATR Auditory and Visual Perception Research Laboratories \\nSeika-cho, Soraku-gun, Kyoto 619-02, JAPAN \\nAbstract \\nWe propose a new parallel-hierarchical neural network model to enable motor \\nlearning for simultaneous control of both trajectory and force, by integrating \\nHogan's control method and our previous neural netw       \n",
       "9               564 \\nPROGRAMMABLE SYNAPTIC CHIP FOR \\nELECTRONIC NEURAL NETWORKS \\nA. Moopenn, H. Langenbacher, A.P. Thakoor, and S.K. Khanna \\nJet Propulsion Laboratory \\nCalifornia Institute of Technology \\nPasadena, CA 91009 \\nABSTRACT \\nA binary synaptic matrix chip has been developed for electronic \\nneural networks. The matrix chip contains a programmable 32X32 \\narray of \"long channel\" NMOSFET binary connection elements imple- \\nmented in a 3-um bulk CMOS process. Since the neurons are kept off- \\nchip, the synapti     \n",
       "10              A Connectionist Symbol Manipulator \\nThat Discovers the Structure of \\nContext-Free Languages \\nMichael C. Mozer and Sreerupa Das \\nDepartment of Computer Science & \\nInstitute of Cognitive Science \\nUniversity of Colorado \\nBoulder, CO 80309-0430 \\nAbstract \\nWe present a neural net architecture that can discover hierarchical and re- \\ncursire structure in symbol strings. To detect structure at multiple levels, \\nthe architecture has the capability of reducing symbols substrings to single \\nsymbols, and ma     \n",
       "11              A Systematic Study of the Input/Output Properties 149 \\nA Systematic Study of the Input/Output Properties \\nof a 2 Compartment Model Neuron \\nWith Active Membranes \\nPaul Rhodes \\nUniversity of California, San Diego \\nABSTRACT \\nThe input/output properties of a 2 compartment model neuron are systematically \\nexplored. Taken from the work of MacGregor (MacGregor, 1987), the model neuron \\ncompartments contain several active conductances, including a potassium conductance in \\nthe dendritic compartment driv       \n",
       "12              A Knowledge-Based Model of Geometry Learning \\nGeoffrey Towell \\nSiemens Corporate Research \\n755 College Road East \\nPrinceton, NJ 08540 \\ntoweli @ learning. siemens. com \\nRichard Lehrer \\nEducational Psychology \\nUniversity of Wisconsin \\n1025 West Johnson St. \\nMadison, WI 53706 \\nIehrer@vms. macc. wisc. edu \\nAbstract \\nWe propose a model of the development of geometric reasoning in children that \\nexplicitly involves learning. The model uses a neural network that is initialized \\nwith an understanding of  \n",
       "13              Limitations of self-organizing maps for \\nvector quantization and multidimensional \\nscaling \\nArthur Flexer \\nThe Austrian Research Institute for Artificial Intelligence \\nSchottengasse 3, A-1010 Vienna, Austria \\nand \\nDepartment of Psychology, University of Vienna \\nLiebiggasse 5, A-1010 Vienna, Austria \\narthur@ai .univie. ac. at \\nAbstract \\nThe limitations of using self-organizing maps (SOM) for either \\nclustering/vector quantization (VQ) or multidimensional scaling \\n(MDS) are being discussed by revi    \n",
       "14              Reinforcement Learning for Mixed \\nOpen-loop and Closed-loop Control \\nEric A. Hansen, Andrew G. Barto, and Shlomo Zilbersteln \\nDepartment of Computer Science \\nUniversity of Massachusetts \\nAmherst, MA 01003 \\nhansen ,barto,shlomo)cs.u mass.edu \\nAbstract \\nClosed-loop control relies on sensory feedback that is usually as- \\nsumed to be free. But if sensing incurs a cost, it may be cost- \\neffective to take sequences of actions in open-loop mode. We de- \\nscribe a reinforcement learning algorithm that       \n",
       "15              Dynamics of On-Line Gradient Descent \\nLearning for Multilayer Neural Networks \\nDavid Saad* \\nDept. of Comp. Sci. & App. Math. \\nAston University \\nBirmingham B4 7ET, UK \\nSara A. Solla t \\nCONNECT, The Niels Bohr Institute \\nBlegdamsdvej 17 \\nCopenhagen 2100, Denmark \\nAbstract \\nWe consider the problem of on-line gradient descent learning for \\ngeneral two-layer neural networks. An analytic solution is pre- \\nsented and used to investigate the role of the learning rate in con- \\ntrolling the evolution and    "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_topic_df.groupby('Dominant Topic').apply(lambda topic_set: (topic_set.sort_values(by=['Contribution %'], \n",
    "                                                                                         ascending=False)\n",
    "                                                                             .iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqQRtvzsRSrs"
   },
   "source": [
    "# Inference on existing papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1666796260709,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "I0QF6K53v4zN",
    "outputId": "55436acd-3bb1-4f5e-c8e8-2c1afac8f997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[622, 829, 440]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_paper_patterns = ['Feudal Reinforcement Learning \\nPeter', 'Illumination-Invariant Face Recognition with a', 'Improved Hidden Markov Model Speech Recognition']\n",
    "sample_paper_idxs = [idx for pattern in sample_paper_patterns \n",
    "                            for idx, content in enumerate(papers) \n",
    "                                if pattern in content]\n",
    "sample_paper_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1666796260709,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "d7JrXUbsw0bt",
    "outputId": "2a645800-435f-462e-a854-7665848e592e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0f2e8c8e-8cd2-454d-a0f1-cc121492574c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>440</td>\n",
       "      <td>7</td>\n",
       "      <td>59.16</td>\n",
       "      <td>word, classifier, classification, training, class, recognition, speech, feature, pattern, trained, character, hmm, sequence, context, mlp, error_rate, speaker, experiment, letter, frame</td>\n",
       "      <td>Improved Hidden Markov Model \\nSpeech Recognition Using \\nRadial Basis Function Networks \\nElliot Singer and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nLexington, MA 02173-9108, USA \\nAbstrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>622</td>\n",
       "      <td>14</td>\n",
       "      <td>47.71</td>\n",
       "      <td>state, action, step, policy, reinforcement_learning, transition, optimal, environment, sequence, task, control, current, path, reward, stochastic, td, goal, trial, agent, probability</td>\n",
       "      <td>Feudal Reinforcement Learning \\nPeter Dayan \\nCNL \\nThe Salk Institute \\nPO Box 85800 \\nSan Diego CA 92186-5800, USA \\ndayanhelmholtz. sdsc. edu \\nGeoffrey E Hinton \\nDepartment of Computer Scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>5</td>\n",
       "      <td>35.76</td>\n",
       "      <td>image, object, feature, pixel, view, face, filter, representation, region, surface, shape, scale, part, edge, visual, location, contour, recognition, transformation, position</td>\n",
       "      <td>Illumination-Invariant Face Recognition with a \\nContrast Sensitive Silicon Retina \\nJoachim M. Buhmann \\nRheinische Friedrich-Wilhelms-Universitfit \\nInstitut ftir Informatik II, R6merstrage 164 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f2e8c8e-8cd2-454d-a0f1-cc121492574c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0f2e8c8e-8cd2-454d-a0f1-cc121492574c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0f2e8c8e-8cd2-454d-a0f1-cc121492574c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     Document  Dominant Topic  Contribution %  \\\n",
       "440       440               7           59.16   \n",
       "622       622              14           47.71   \n",
       "829       829               5           35.76   \n",
       "\n",
       "                                                                                                                                                                                    Topic Desc  \\\n",
       "440  word, classifier, classification, training, class, recognition, speech, feature, pattern, trained, character, hmm, sequence, context, mlp, error_rate, speaker, experiment, letter, frame   \n",
       "622     state, action, step, policy, reinforcement_learning, transition, optimal, environment, sequence, task, control, current, path, reward, stochastic, td, goal, trial, agent, probability   \n",
       "829             image, object, feature, pixel, view, face, filter, representation, region, surface, shape, scale, part, edge, visual, location, contour, recognition, transformation, position   \n",
       "\n",
       "                                                                                                                                                                                                       Paper  \n",
       "440  Improved Hidden Markov Model \\nSpeech Recognition Using \\nRadial Basis Function Networks \\nElliot Singer and Richard P. Lippmann \\nLincoln Laboratory, MIT \\nLexington, MA 02173-9108, USA \\nAbstrac...  \n",
       "622  Feudal Reinforcement Learning \\nPeter Dayan \\nCNL \\nThe Salk Institute \\nPO Box 85800 \\nSan Diego CA 92186-5800, USA \\ndayanhelmholtz. sdsc. edu \\nGeoffrey E Hinton \\nDepartment of Computer Scien...  \n",
       "829  Illumination-Invariant Face Recognition with a \\nContrast Sensitive Silicon Retina \\nJoachim M. Buhmann \\nRheinische Friedrich-Wilhelms-Universitfit \\nInstitut ftir Informatik II, R6merstrage 164 ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200)\n",
    "(corpus_topic_df[corpus_topic_df['Document']\n",
    "                 .isin(sample_paper_idxs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1S84f-T7RVED"
   },
   "source": [
    "# Topic Inference on New Papers (Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1666796260709,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "50rVOoraO48k",
    "outputId": "b099b8c8-e0d4-44d6-ae24-aca4642186e1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nUnsupervised Translation of Programming Languages\\nMarie-Anne Lachaux, Baptiste Roziere, Lowik Chanussot, Guillaume Lample\\nA transcompiler, also known as source-to-source translator, is a system that converts source code \\nfrom a high-level programming language (such as C++ or Python) to another. \\nTranscompilers are primarily used for interoperability, and to port codebases \\nwritten in an obsolete or deprecated language (e.g. COBOL, Python 2) to a modern one. \\nThey typically rely on handcrafted rewrite rules, applied to the source code abstract syntax tree. \\nUnfortunately, the resulting translations often lack readability, fail to respect the target language conventions, \\nand require manual modifications in order to work properly. \\nThe overall translation process is timeconsuming and requires expertise in both the source and target languages, \\nmaking code-translation projects expensive. \\nAlthough neural models significantly outperform their rule-based counterparts in the context of natural language translation, \\ntheir applications to transcompilation have been limited due to the scarcity of parallel data in this domain. \\nIn this paper, we propose to leverage recent approaches in unsupervised machine translation to train a fully \\nunsupervised neural transcompiler. We train our model on source code from open source GitHub projects, \\nand show that it can translate functions between C++, Java, and Python with high accuracy. \\nOur method relies exclusively on monolingual source code, requires no expertise in the source or target languages, \\nand can easily be generalized to other programming languages. We also build and release a test set composed of 852 \\nparallel functions, along with unit tests to check the correctness of translations. \\nWe show that our model outperforms rule-based commercial baselines by a significant margin.\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_paper = \"\"\"\n",
    "Unsupervised Translation of Programming Languages\n",
    "Marie-Anne Lachaux, Baptiste Roziere, Lowik Chanussot, Guillaume Lample\n",
    "A transcompiler, also known as source-to-source translator, is a system that converts source code \n",
    "from a high-level programming language (such as C++ or Python) to another. \n",
    "Transcompilers are primarily used for interoperability, and to port codebases \n",
    "written in an obsolete or deprecated language (e.g. COBOL, Python 2) to a modern one. \n",
    "They typically rely on handcrafted rewrite rules, applied to the source code abstract syntax tree. \n",
    "Unfortunately, the resulting translations often lack readability, fail to respect the target language conventions, \n",
    "and require manual modifications in order to work properly. \n",
    "The overall translation process is timeconsuming and requires expertise in both the source and target languages, \n",
    "making code-translation projects expensive. \n",
    "Although neural models significantly outperform their rule-based counterparts in the context of natural language translation, \n",
    "their applications to transcompilation have been limited due to the scarcity of parallel data in this domain. \n",
    "In this paper, we propose to leverage recent approaches in unsupervised machine translation to train a fully \n",
    "unsupervised neural transcompiler. We train our model on source code from open source GitHub projects, \n",
    "and show that it can translate functions between C++, Java, and Python with high accuracy. \n",
    "Our method relies exclusively on monolingual source code, requires no expertise in the source or target languages, \n",
    "and can easily be generalized to other programming languages. We also build and release a test set composed of 852 \n",
    "parallel functions, along with unit tests to check the correctness of translations. \n",
    "We show that our model outperforms rule-based commercial baselines by a significant margin.\n",
    "\"\"\"\n",
    "\n",
    "new_paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOY_6U8zRYkb"
   },
   "source": [
    "## Pre-process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1666796260709,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "e0I7hWMGPQ_q",
    "outputId": "a7e601b6-1088-4897-ce8e-8f1bbeeadec4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 214.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unsupervised', 'translation', 'programming', 'language', 'marie', 'anne', 'lachaux', 'baptiste', 'roziere', 'lowik', 'chanussot', 'guillaume', 'lample', 'transcompiler', 'also', 'known', 'source', 'source', 'translator', 'system', 'convert', 'source', 'code', 'high', 'level', 'programming', 'language', 'python', 'another', 'transcompilers']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_papers = normalize_corpus([new_paper])\n",
    "print(preprocessed_papers[0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wkf7nKhURaYX"
   },
   "source": [
    "## Generate Influential Bi-grams if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666796260710,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "lUzIztYHPYeU",
    "outputId": "a46e86b4-bca8-4931-f74c-ef5911a44b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rule', 'based', 'counterpart', 'context', 'natural_language', 'translation', 'application', 'transcompilation', 'limited', 'due']\n"
     ]
    }
   ],
   "source": [
    "bigrams_corpus = [bigram_model[doc] for doc in preprocessed_papers]\n",
    "print(bigrams_corpus[0][90:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NWsbx_cRep7"
   },
   "source": [
    "## Generate BOW Vectors from Training Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1666796260711,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "ypm5UXrZPtC6",
    "outputId": "f8381bb8-bf2d-464a-c8d2-2278811500f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(20, 1), (25, 1), (84, 1), (134, 1), (138, 1), (200, 2), (256, 1), (285, 2), (329, 1), (351, 1), (353, 1), (407, 1), (422, 1), (425, 1), (471, 1), (531, 1), (575, 1), (576, 7), (636, 1), (651, 1), (722, 1), (742, 1), (858, 1), (865, 1), (899, 1), (903, 2), (942, 2), (964, 1), (1030, 1), (1051, 1)]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in bigrams_corpus]\n",
    "print(bow_corpus[0][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqXuFNw3RiLg"
   },
   "source": [
    "## Use trained topic model to predict topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1666796260711,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "zWSAMumoQGTB",
    "outputId": "8f1736b8-040c-427c-a0f5-fabd88fa6e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('although', 1), ('another', 1), ('composed', 1), ('domain', 1), ('easily', 1), ('high', 2), ('limited', 1), ('neural', 2), ('properly', 1), ('require', 1), ('resulting', 1), ('test', 1), ('typically', 1), ('unit', 1), ('applied', 1), ('due', 1), ('lack', 1), ('language', 7), ('recent', 1), ('rewrite', 1), ('abstract', 1), ('application', 1), ('known', 1), ('level', 1), ('open', 1), ('parallel', 2), ('requires', 2), ('significant', 1), ('accuracy', 1), ('along', 1)]\n"
     ]
    }
   ],
   "source": [
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[0][:30]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsQlCfP2Rmpp"
   },
   "source": [
    "## Show most relevant topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1870,
     "status": "ok",
     "timestamp": 1666796263908,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "7ly1ZQkzQLhW",
    "outputId": "d550673e-8107-4120-bbaf-06696d8f2839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.03516174402250352),\n",
       " (1, 0.06399437412095639),\n",
       " (2, 0.048523206751054856),\n",
       " (3, 0.059774964838255965),\n",
       " (4, 0.06962025316455693),\n",
       " (5, 0.03305203938115331),\n",
       " (6, 0.11884669479606189),\n",
       " (7, 0.043600562587904367),\n",
       " (8, 0.08579465541490855),\n",
       " (9, 0.07665260196905764),\n",
       " (10, 0.042897327707454296),\n",
       " (11, 0.15611814345991562),\n",
       " (12, 0.08438818565400841),\n",
       " (13, 0.04008438818565402),\n",
       " (14, 0.041490857946554154)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_topics = best_lda_model[bow_corpus][0]\n",
    "predicted_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666796263908,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "QTYgVVlRQUU4",
    "outputId": "2e132b99-03f2-451e-e542-aa9feac6f480"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 0.15611814345991562)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic = max(predicted_topics, key=lambda x: x[1])\n",
    "top_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1666796263909,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "1MypZEfwQbrl",
    "outputId": "fdb53f22-3cbe-4327-a930-1bae8a325fb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topic_idx = top_topic[0]\n",
    "top_topic_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666796265287,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "sI3XLFfkQrPo",
    "outputId": "6773772a-b07b-4d33-efdf-d2a9388bfd8f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4ca85dbf-b539-4730-b599-44678ec50159\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>rule, task, search, table, experiment, test, instance, feature, domain, technique, machine, training, application, user, query, accuracy, knowledge, measure, type, run</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ca85dbf-b539-4730-b599-44678ec50159')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4ca85dbf-b539-4730-b599-44678ec50159 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4ca85dbf-b539-4730-b599-44678ec50159');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                                                                                                                                 Terms per Topic\n",
       "Topic12  rule, task, search, table, experiment, test, instance, feature, domain, technique, machine, training, application, user, query, accuracy, knowledge, measure, type, run"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df.iloc[[top_topic_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1666796265990,
     "user": {
      "displayName": "Ekaterina Butyugina",
      "userId": "10324182844490961884"
     },
     "user_tz": -120
    },
    "id": "W1VYw5guQ01h",
    "outputId": "b0193e92-9772-4e86-a665-1e2d9dc33cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsupervised Translation of Programming Languages\n",
      "Marie-Anne Lachaux, Baptiste Roziere, Lowik Chanussot, Guillaume Lample\n",
      "A transcompiler, also known as source-to-source translator, is a system that converts source code \n",
      "from a high-level programming language (such as C++ or Python) to another. \n",
      "Transcompilers are primarily used for interoperability, and to port codebases \n",
      "written in an obsolete or deprecated language (e.g. COBOL, Python 2) to a modern one. \n",
      "They typically rely on handcrafted rewrite rules, applied to the source code abstract syntax tree. \n",
      "Unfortunately, the resulting translations often lack readability, fail to respect the target language conventions, \n",
      "and require manual modifications in order to work properly. \n",
      "The overall translation process is timeconsuming and requires expertise in both the source and target languages, \n",
      "making code-translation projects expensive. \n",
      "Although neural models significantly outperform their rule-based counterparts in the context of natural language translation, \n",
      "their applications to transcompilation have been limited due to the scarcity of parallel data in this domain. \n",
      "In this paper, we propose to leverage recent approaches in unsupervised machine translation to train a fully \n",
      "unsupervised neural transcompiler. We train our model on source code from open source GitHub projects, \n",
      "and show that it can translate functions between C++, Java, and Python with high accuracy. \n",
      "Our method relies exclusively on monolingual source code, requires no expertise in the source or target languages, \n",
      "and can easily be generalized to other programming languages. We also build and release a test set composed of 852 \n",
      "parallel functions, along with unit tests to check the correctness of translations. \n",
      "We show that our model outperforms rule-based commercial baselines by a significant margin.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(new_paper)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
